{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used to sanity-check data: plotting raw and written files, calculating various statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:14.394034Z",
     "iopub.status.busy": "2025-01-15T20:31:14.393421Z",
     "iopub.status.idle": "2025-01-15T20:31:15.405491Z",
     "shell.execute_reply": "2025-01-15T20:31:15.404805Z",
     "shell.execute_reply.started": "2025-01-15T20:31:14.393962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:15.407062Z",
     "iopub.status.busy": "2025-01-15T20:31:15.406656Z",
     "iopub.status.idle": "2025-01-15T20:31:15.410059Z",
     "shell.execute_reply": "2025-01-15T20:31:15.409600Z",
     "shell.execute_reply.started": "2025-01-15T20:31:15.407042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_hr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048high/stsabl2048high.zarr\"\n",
    "raw_jhf_hr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.000.nc\"\n",
    "raw_jhf_hr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.001.nc\"\n",
    "raw_jhf_hr_104_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.104.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:15.410823Z",
     "iopub.status.busy": "2025-01-15T20:31:15.410676Z",
     "iopub.status.idle": "2025-01-15T20:31:15.483014Z",
     "shell.execute_reply": "2025-01-15T20:31:15.482366Z",
     "shell.execute_reply.started": "2025-01-15T20:31:15.410811Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr = zarr.open(stored_jhf_hr_path)\n",
    "jhf_hr_netcdf_t0 = xr.open_dataset(raw_jhf_hr_0_path)\n",
    "jhf_hr_netcdf_t1 = xr.open_dataset(raw_jhf_hr_1_path)\n",
    "jhf_hr_netcdf_t104 = xr.open_dataset(raw_jhf_hr_104_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:15.484379Z",
     "iopub.status.busy": "2025-01-15T20:31:15.484221Z",
     "iopub.status.idle": "2025-01-15T20:31:15.517448Z",
     "shell.execute_reply": "2025-01-15T20:31:15.516827Z",
     "shell.execute_reply.started": "2025-01-15T20:31:15.484364Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_lr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048low/stsabl2048low.zarr\"\n",
    "raw_jhf_lr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.000.nc\"\n",
    "raw_jhf_lr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.001.nc\"\n",
    "raw_jhf_lr_19_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.019.nc\"\n",
    "\n",
    "\n",
    "jhf_lr_zarr = zarr.open(stored_jhf_lr_path)\n",
    "jhf_lr_netcdf_t0 = xr.open_dataset(raw_jhf_lr_0_path)\n",
    "jhf_lr_netcdf_t1 = xr.open_dataset(raw_jhf_lr_1_path)\n",
    "jhf_lr_netcdf_t19 = xr.open_dataset(raw_jhf_lr_19_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"cyan\">\n",
    "\n",
    "# Remember, data is saved in `nnz-nny-nnx`\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Quick-Verify Correctness of data\n",
    "\n",
    "1. Check if `data == 0`\n",
    "\n",
    "2. Pick one $64^3$ chunk and compare it to raw NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### `zarr.info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['velocity'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Indexing, Compare to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Checking whether field all zeros - True is bad!\")\n",
    "\n",
    "for t in range(105):\n",
    "    print(\"t=\", t, \" - \", np.all(jhf_hr_zarr['temperature'][t,:64,:64,:64,0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][1,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-01-15T14:50:41.857673Z",
     "shell.execute_reply": "2025-01-15T14:50:41.857091Z",
     "shell.execute_reply.started": "2025-01-15T14:44:20.357009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  97 True\n",
      "t:  98 True\n",
      "t:  99 True\n",
      "t:  100 True\n",
      "t:  101 True\n",
      "t:  102 True\n",
      "t:  103 True\n",
      "t:  104 True\n"
     ]
    }
   ],
   "source": [
    "for t in range(93, 105):\n",
    "    zarr_comparison_data = jhf_hr_zarr['temperature'][t,:64,:64,:64,0]\n",
    "\n",
    "    raw_t_path = f\"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.{t:03d}.nc\"\n",
    "    raw_xr = xr.open_dataset(raw_t_path)\n",
    "    raw_t = raw_xr['t'].isel(nnx=slice(0, 64), nny=slice(0, 64), nnz=slice(0, 64)).values\n",
    "    \n",
    "    print(\"t: \", t, np.all(zarr_comparison_data == raw_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,0,0,:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_hr_netcdf_t0['e'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Xarray complains about missing metadata. NOT Fixed by GPT o1\n",
    "\n",
    "`written_ds_xr = xr.open_dataset(stored_jhf_path, engine='zarr', consolidated=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][0, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['energy'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_lr_netcdf_t0['t'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Efficient Zarr full data Slices\n",
    "\n",
    "This can take a few minutes\n",
    "\n",
    " Sciserver doesn't allow localhost connections, so can't use Dask Cluster console Sciserver doesn't allow localhost connections, so can't use Dask Cluster console\n",
    " \n",
    "<font color=\"green\"> Lazy loading speeds up reading times 10x+</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T17:36:10.638762Z",
     "iopub.status.busy": "2025-01-15T17:36:10.638516Z",
     "iopub.status.idle": "2025-01-15T17:36:10.651136Z",
     "shell.execute_reply": "2025-01-15T17:36:10.650513Z",
     "shell.execute_reply.started": "2025-01-15T17:36:10.638744Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "def process_zarr(stored_jhf_path, dataset):\n",
    "    if dataset not in ['hr', 'lr']:\n",
    "        raise ValueError(\"Dataset must be 'hr' or 'lr'.\")\n",
    "\n",
    "    # Open the Zarr group\n",
    "    store = zarr.open_group(stored_jhf_path, mode='r')\n",
    "\n",
    "    # Create Dask arrays\n",
    "    data_arrays = {}\n",
    "    variables = list(store.array_keys())\n",
    "    for var_name in variables:\n",
    "        zarr_array = store[var_name]\n",
    "        dask_array = da.from_zarr(zarr_array)\n",
    "        # Squeeze scalar variables\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)\n",
    "        data_arrays[var_name] = dask_array\n",
    "\n",
    "    # Function to collect data slices\n",
    "    def collect_data_slices(data_arrays, variables, timesteps):\n",
    "        data_slices = []\n",
    "        titles = []\n",
    "        \n",
    "        for variable in variables:\n",
    "            for timestep in timesteps:\n",
    "                dask_array = data_arrays[variable]\n",
    "                \n",
    "                # Get slices along each dimension (assuming shape = [time, Z, Y, X] or similar)\n",
    "                x_slice = dask_array[timestep, :, :, 0]\n",
    "                y_slice = dask_array[timestep, :, 0, :]\n",
    "                z_slice = dask_array[timestep, 0, :, :]\n",
    "                \n",
    "                # For vector variables, handle components\n",
    "                if variable == 'velocity':\n",
    "                    for component in range(3):\n",
    "                        x_comp_slice = x_slice[..., component]\n",
    "                        y_comp_slice = y_slice[..., component]\n",
    "                        z_comp_slice = z_slice[..., component]\n",
    "                        \n",
    "                        data_slices.extend([x_comp_slice, y_comp_slice, z_comp_slice])\n",
    "                        titles.extend([\n",
    "                            f\"{variable} (component {component}) nnx=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nny=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nnz=0 Timestep={timestep}\"\n",
    "                        ])\n",
    "                else:\n",
    "                    data_slices.extend([x_slice, y_slice, z_slice])\n",
    "                    titles.extend([\n",
    "                        f\"{variable} nnx=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nny=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nnz=0 Timestep={timestep}\"\n",
    "                    ])\n",
    "        return data_slices, titles\n",
    "\n",
    "    # Choose timesteps: here every 5th until the end\n",
    "    timesteps = range(0, data_arrays['energy'].shape[0], 5)  \n",
    "\n",
    "    # Collect data slices\n",
    "    data_slices, titles = collect_data_slices(data_arrays, ['energy', 'temperature', 'pressure', 'velocity'], timesteps)\n",
    "\n",
    "    # Compute all data slices at once (lazy -> single compute call)\n",
    "    with ProgressBar():\n",
    "        computed_slices = compute(*data_slices)\n",
    "\n",
    "    # Plot (and now save) all images\n",
    "    # Create a master folder for all slices\n",
    "    master_folder = os.path.join(\"zarr_slices\", dataset)\n",
    "    os.makedirs(master_folder, exist_ok=True)\n",
    "\n",
    "    idx = 0\n",
    "    for variable in ['energy', 'temperature', 'pressure', 'velocity']:\n",
    "        # Make a folder per variable\n",
    "        var_folder = os.path.join(master_folder, variable)\n",
    "        os.makedirs(var_folder, exist_ok=True)\n",
    "        \n",
    "        # We'll have 3 slices per timestep if scalar,\n",
    "        # or 9 slices per timestep if velocity (3 components * 3 slices).\n",
    "        # So we figure out how many slices belong to each variable:\n",
    "        if variable == 'velocity':\n",
    "            slices_per_timestep = 9\n",
    "        else:\n",
    "            slices_per_timestep = 3\n",
    "        \n",
    "        for timestep in timesteps:\n",
    "            # For velocity, we handle 9 images; for others, 3.\n",
    "            subset = computed_slices[idx : idx + slices_per_timestep]\n",
    "            subset_titles = titles[idx : idx + slices_per_timestep]\n",
    "            \n",
    "            for data_slice, title in zip(subset, subset_titles):\n",
    "                plt.figure()\n",
    "                plt.imshow(data_slice)\n",
    "                plt.title(title)\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.colorbar()\n",
    "                \n",
    "                # Create a filename for saving\n",
    "                safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                filename = os.path.join(var_folder, f\"Timestep_{timestep}_{safe_title}.png\")\n",
    "                plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            \n",
    "            idx += slices_per_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T17:36:10.779513Z",
     "iopub.status.busy": "2025-01-15T17:36:10.779371Z",
     "iopub.status.idle": "2025-01-15T17:37:53.271401Z",
     "shell.execute_reply": "2025-01-15T17:37:53.270752Z",
     "shell.execute_reply.started": "2025-01-15T17:36:10.779500Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 52.64 s\n"
     ]
    }
   ],
   "source": [
    "process_zarr(stored_jhf_lr_path, \"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Statistics - Mean Temp. across Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:57:27.396553Z",
     "iopub.status.busy": "2025-01-15T20:57:27.396285Z",
     "iopub.status.idle": "2025-01-15T20:57:28.824951Z",
     "shell.execute_reply": "2025-01-15T20:57:28.824194Z",
     "shell.execute_reply.started": "2025-01-15T20:57:27.396535Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.array as da\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_slices_and_mean_z(\n",
    "    ds_zarr_group, \n",
    "    variables, \n",
    "    time_start=0, \n",
    "    time_stop=105, \n",
    "    time_step=5, \n",
    "    z_step=128,\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Creates a Dask array for each variable from the Zarr group ds_zarr_group.\n",
    "    2) Gathers slice arrays (X=0, Y=0, Z=0) for each variable/time.\n",
    "    3) Gathers the mean-temp-across-Z (every z_step along Z).\n",
    "    4) Performs exactly one .compute() to load everything.\n",
    "    5) Plots and saves images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_zarr_group : zarr.hierarchy.Group\n",
    "        A Zarr group, e.g. from zarr.open_group(...), with arrays named by `variables`.\n",
    "        Each array shape typically [time, z, y, x, 1 or 3].\n",
    "    variables : list of str\n",
    "        E.g. [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "    time_start, time_stop, time_step : int\n",
    "        We will process times in range(time_start, time_stop, time_step).\n",
    "        Make sure time_stop <= ds['temperature'].shape[0].\n",
    "    z_step : int\n",
    "        Step size along Z dimension for the mean calculation (and plot).\n",
    "    \"\"\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Convert each Zarr array to a Dask array (lazy)\n",
    "    #    ds_zarr_group[var] is a zarr Array; we want da.Array for each var\n",
    "    # -------------------------------------------------------------------------\n",
    "    data_arrays = {}\n",
    "    for var in variables:\n",
    "        zarr_array = ds_zarr_group[var]  # shape e.g. (105, 2048, 2048, 2048, 1)\n",
    "        dask_array = da.from_zarr(zarr_array)  # now a Dask array, fully lazy\n",
    "        # If last dim == 1, squeeze it out\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)  # shape => (time, z, y, x)\n",
    "        data_arrays[var] = dask_array\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Build a range of timesteps as slice objects (NOT a for-loop yet)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll do time slicing using slice(time_start, time_stop, time_step).\n",
    "    # For example, if time_start=0, time_stop=105, time_step=5 => times = 0..100\n",
    "    # This is a single slice if you want standard 0,5,10,... indexing.\n",
    "    # But if you truly need [0, 5, 10, ...], that's still a step slice.\n",
    "    # NOTE: This requires that time_stop < shape[0]. E.g. shape[0]=105 => last valid index=104\n",
    "    time_slice = slice(time_start, time_stop, time_step)\n",
    "    # We'll confirm that time_stop <= data_arrays[any_var].shape[0]\n",
    "    # but let's assume user does that.\n",
    "\n",
    "    # We'll also define z-slice for the mean. E.g. z_slice = slice(None, None, z_step)\n",
    "    # i.e. every z_step along that axis\n",
    "    z_slice = slice(None, None, z_step)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3a) Gather the Dask slice arrays for X=0, Y=0, Z=0\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll store them in lists along with their eventual plot titles\n",
    "    slice_arrays = []\n",
    "    slice_titles = []\n",
    "\n",
    "    for var in variables:\n",
    "        arr = data_arrays[var]  # shape e.g. [time, z, y, x] (for scalars) or [time, z, y, x, 3] (if not squeezed)\n",
    "        # We'll do a standard shape: (time, z, y, x) for scalars\n",
    "        # For velocity, we do shape => (time, z, y, x, 3). If you have that, you'd handle differently.\n",
    "\n",
    "        # We'll produce these slices for the times in time_slice (i.e. arr[time_slice, ...]):\n",
    "        #   x=0 => arr[:, :, :, 0]\n",
    "        #   y=0 => arr[:, :, 0, :]\n",
    "        #   z=0 => arr[:, 0, :, :]\n",
    "        # But we still want to only pick the times in [time_slice].\n",
    "        # So for each slice, we do e.g. arr[time_slice, :, :, 0].\n",
    "        # We'll keep them as separate arrays.\n",
    "\n",
    "        # If it's \"velocity\" and has shape [time, z, y, x, 3], do 3 components\n",
    "        if var == \"velocity\" and arr.ndim == 5:\n",
    "            # arr.shape => (time, z, y, x, 3)\n",
    "            # We want x=0 => arr[time_slice, :, :, 0, comp]\n",
    "            # Similarly y=0 => arr[time_slice, :, 0, :, comp]\n",
    "            # etc. We'll build 3 slices for each comp\n",
    "            for comp in range(3):\n",
    "                # x=0\n",
    "                vx0 = arr[time_slice, :, :, 0, comp]\n",
    "                slice_arrays.append(vx0)\n",
    "                slice_titles.append(f\"{var} (component {comp}) x=0\")\n",
    "\n",
    "                # y=0\n",
    "                vy0 = arr[time_slice, :, 0, :, comp]\n",
    "                slice_arrays.append(vy0)\n",
    "                slice_titles.append(f\"{var} (component {comp}) y=0\")\n",
    "\n",
    "                # z=0\n",
    "                vz0 = arr[time_slice, 0, :, :, comp]\n",
    "                slice_arrays.append(vz0)\n",
    "                slice_titles.append(f\"{var} (component {comp}) z=0\")\n",
    "\n",
    "        else:\n",
    "            # Scalar variable shape => (time, z, y, x)\n",
    "            # x=0\n",
    "            x0 = arr[time_slice, :, :, 0]\n",
    "            slice_arrays.append(x0)\n",
    "            slice_titles.append(f\"{var} x=0\")\n",
    "\n",
    "            # y=0\n",
    "            y0 = arr[time_slice, :, 0, :]\n",
    "            slice_arrays.append(y0)\n",
    "            slice_titles.append(f\"{var} y=0\")\n",
    "\n",
    "            # z=0\n",
    "            z0 = arr[time_slice, 0, :, :]\n",
    "            slice_arrays.append(z0)\n",
    "            slice_titles.append(f\"{var} z=0\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3b) Gather the Dask array for \"mean temperature across Z\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll only do this for the \"temperature\" variable if it exists\n",
    "    mean_temp_dask = None\n",
    "    if \"temperature\" in data_arrays:\n",
    "        temp_arr = data_arrays[\"temperature\"]  # shape [time, z, y, x]\n",
    "        # We'll slice time => [time_slice], and z => [::z_step], then mean over (y,x).\n",
    "        # But if we do a step for z, we can do e.g. temp_arr[time_slice, ::z_step, :, :]\n",
    "        # That is standard slicing (no list-of-indices).\n",
    "        # Then .mean(axis=[2,3]) => shape: [num_times, number_of_z_samples]\n",
    "        stepped = temp_arr[time_slice, z_slice, :, :]\n",
    "        mean_temp_dask = stepped.mean(axis=(2, 3))  # shape => [num_times, # of z_slices]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Single .compute() for all\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll combine all slice arrays + mean_temp_dask into one big list\n",
    "    # and do exactly one .compute().\n",
    "    to_compute = []\n",
    "    to_compute.extend(slice_arrays)  # each is a Dask array of shape [num_times, ...]\n",
    "    if mean_temp_dask is not None:\n",
    "        to_compute.append(mean_temp_dask)\n",
    "\n",
    "    # If there's nothing to compute, just return\n",
    "    if not to_compute:\n",
    "        print(\"No data to compute. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Building Dask graph. No data is read yet. Now calling .compute() with a ProgressBar...\")\n",
    "    os.makedirs(master_slice_folder, exist_ok=True)\n",
    "    os.makedirs(mean_output_folder, exist_ok=True)\n",
    "\n",
    "    with ProgressBar():\n",
    "        results = compute(*to_compute)\n",
    "\n",
    "    # results is a tuple of length = len(to_compute).\n",
    "    # The first len(slice_arrays) items are the slice results,\n",
    "    # the last item (if present) is mean_temp_dask.\n",
    "\n",
    "    slice_results = results[:len(slice_arrays)]\n",
    "    mean_results = results[-1] if mean_temp_dask is not None else None\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Plot the slice results\n",
    "    #    - Each slice result is shape [num_times, ...], so we must loop\n",
    "    #      over the timesteps to produce separate images.\n",
    "    # -------------------------------------------------------------------------\n",
    "    times = list(range(time_start, time_stop, time_step))  # e.g. [0,5,10,...]\n",
    "\n",
    "    idx = 0\n",
    "    for slice_result, title in zip(slice_results, slice_titles):\n",
    "        # slice_result shape => [num_times, z, y?], depends if x=0 vs y=0 vs z=0\n",
    "        # We want one image per time. So if slice_result.shape[0] is # of timesteps,\n",
    "        # we do a for-loop:\n",
    "        for i, t in enumerate(times):\n",
    "            single_time_slice = slice_result[i]  # shape => e.g. [z, y], etc.\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(single_time_slice)\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.colorbar()\n",
    "            plt.title(f\"{title}, t={t}\")\n",
    "\n",
    "            safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "            fname = os.path.join(master_slice_folder, f\"{safe_title}_t_{t}.png\")\n",
    "            plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    print(\"Done retrieving the data! Plotting and Saving!\")\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Plot the mean temperature results\n",
    "    # -------------------------------------------------------------------------\n",
    "    if mean_results is not None:\n",
    "        # shape => [num_times, # of z_slices]\n",
    "        # We'll plot each row\n",
    "        # The z_slices are from z=0..2048..z_step, so let's build that list\n",
    "        z_indices_list = list(range(0, data_arrays[\"temperature\"].shape[1], z_step))\n",
    "        for i, t in enumerate(times):\n",
    "            row = mean_results[i, :]  # shape [# of z_slices]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(z_indices_list, row)\n",
    "            plt.title(f\"Mean Temperature across Z (t={t})\")\n",
    "            plt.xlabel(\"Z index\")\n",
    "            plt.ylabel(\"Avg Temp\")\n",
    "            \n",
    "            print(\"Means for t: \", row)\n",
    "\n",
    "            fname = os.path.join(mean_output_folder, f\"mean_z_temperature_t_{t}.png\")\n",
    "            plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved plot as {fname}\")\n",
    "\n",
    "    print(\"All done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### High Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:57:36.579839Z",
     "iopub.status.busy": "2025-01-15T20:57:36.579013Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Dask graph. No data is read yet. Now calling .compute() with a ProgressBar...\n",
      "[#########                               ] | 23% Completed | 391.75 s"
     ]
    }
   ],
   "source": [
    "variables = [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "\n",
    "plot_slices_and_mean_z(\n",
    "    ds_zarr_group=jhf_hr_zarr,\n",
    "    variables=variables,\n",
    "    time_start=0,\n",
    "    time_stop=105,  # up to but not including 105 => indices 0..104\n",
    "    time_step=5,\n",
    "    z_step=16,\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-15T14:53:23.702012Z",
     "iopub.status.idle": "2025-01-15T14:53:23.702232Z",
     "shell.execute_reply": "2025-01-15T14:53:23.702126Z",
     "shell.execute_reply.started": "2025-01-15T14:53:23.702117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_mean_temp_across_z(data_arrays, timesteps=range(0, 106, 5), data_type=\"original\", spacing=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across X\n",
    "\n",
    "- [ ] TODO if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compare Zarr to NetCDF correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask import compute\n",
    "\n",
    "def compare_zarr_and_netcdf_allvars(\n",
    "    zarr_group,\n",
    "    netcdf_path_pattern,\n",
    "    times=range(0, 105),  # valid time indices\n",
    "    z_slice=64,\n",
    "    y_slice=64,\n",
    "    x_slice=64,\n",
    "    netcdf_chunk=64,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare all JHF variables between a Zarr group and multiple NetCDF files \n",
    "    for the given timesteps, using lazy Dask operations in one pass.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zarr_group : zarr.hierarchy.Group\n",
    "        Zarr group containing the 4 JHF variables:\n",
    "        [\"temperature\", \"pressure\", \"energy\", \"velocity\"].\n",
    "        Each variable is shape [time, z, y, x, (1 or 3)].\n",
    "    netcdf_path_pattern : str\n",
    "        File path pattern for NetCDF files. \n",
    "        E.g. \"/path/to/jhf.*.nc\" if each file is one timestep.\n",
    "    times : iterable\n",
    "        Timestep indices (e.g. range(0,105)) to compare in one go.\n",
    "    z_slice, y_slice, x_slice : int\n",
    "        Compare subregion [0:z_slice, 0:y_slice, 0:x_slice].\n",
    "        Typically something small for quick checks (64, 128, etc.).\n",
    "    netcdf_chunk : int\n",
    "        Chunk size to use for opening NetCDF \n",
    "        (e.g. 64 => chunks={\"nnz\": 64, \"nny\": 64, \"nnx\": 64}).\n",
    "    \"\"\"\n",
    "\n",
    "    #---------------------\n",
    "    # 1) OPEN NETCDF\n",
    "    #---------------------\n",
    "    ds_nc = xr.open_mfdataset(\n",
    "        netcdf_path_pattern,\n",
    "        combine=\"nested\",\n",
    "        concat_dim=\"time\",\n",
    "        parallel=True,\n",
    "        chunks={\"nnz\": netcdf_chunk, \"nny\": netcdf_chunk, \"nnx\": netcdf_chunk}\n",
    "    )\n",
    "    # The NetCDF variables we expect: \"t\", \"p\", \"e\", \"u\", \"v\", \"w\"\n",
    "    # Each file is presumably one time step, stacked along \"time\".\n",
    "\n",
    "    #---------------------\n",
    "    # 2) PREP Zarr as Dask arrays\n",
    "    #---------------------\n",
    "    # We'll create xarray or Dask arrays from the Zarr group.\n",
    "    # That ensures everything is truly lazy until .compute().\n",
    "    import xarray as xr\n",
    "    var_map = {}\n",
    "    for var in [\"temperature\", \"pressure\", \"energy\", \"velocity\"]:\n",
    "        zarr_array = zarr_group[var]  # e.g. shape [time, z, y, x, 3 or 1]\n",
    "        # Convert to a Dask array:\n",
    "        dask_arr = da.from_zarr(zarr_array)\n",
    "        # If last dim == 1, squeeze it out so shape becomes [time, z, y, x]\n",
    "        if dask_arr.shape[-1] == 1:\n",
    "            dask_arr = dask_arr.squeeze(axis=-1)\n",
    "        # Wrap it in an xarray.DataArray for easier .isel():\n",
    "        var_map[var] = xr.DataArray(\n",
    "            dask_arr,\n",
    "            dims=(\"time\", \"z\", \"y\", \"x\") if var != \"velocity\" else (\"time\", \"z\", \"y\", \"x\", \"component\")\n",
    "        )\n",
    "\n",
    "    #---------------------\n",
    "    # 3) BUILD COMPARISON\n",
    "    #---------------------\n",
    "    # We'll compare these variable pairs:\n",
    "    #   Zarr => NetCDF\n",
    "    #   \"temperature\" => \"t\"\n",
    "    #   \"pressure\"    => \"p\"\n",
    "    #   \"energy\"      => \"e\"\n",
    "    #   \"velocity\"[..., comp=0] => \"u\"\n",
    "    #   \"velocity\"[..., comp=1] => \"v\"\n",
    "    #   \"velocity\"[..., comp=2] => \"w\"\n",
    "    # We'll gather all eq_arrays in a list, then do one single compute.\n",
    "    eq_arrays = []\n",
    "    eq_descriptions = []\n",
    "\n",
    "    # Helper to slice netcdf\n",
    "    def slice_nc(var_name):\n",
    "        return ds_nc[var_name].isel(\n",
    "            time=times, \n",
    "            nnz=slice(0, z_slice), \n",
    "            nny=slice(0, y_slice), \n",
    "            nnx=slice(0, x_slice)\n",
    "        )\n",
    "    # Helper to slice zarr\n",
    "    def slice_zarr(var_name):\n",
    "        # if \"velocity\", we'll handle it separately below\n",
    "        return var_map[var_name].isel(\n",
    "            time=slice(min(times), max(times)+1),  # a bit broader, then we'll index in a second step\n",
    "            z=slice(0, z_slice),\n",
    "            y=slice(0, y_slice),\n",
    "            x=slice(0, x_slice),\n",
    "        ).isel(time=times if isinstance(times, list) else range(len(times)))\n",
    "        # Explanation: if `times` is e.g. range(0,105,5), xarray can handle slice. \n",
    "        # If you pass a range object directly, xarray handles it. \n",
    "        # Or we cast to a list to ensure it can index properly.\n",
    "\n",
    "    # Compare temperature => t\n",
    "    if \"temperature\" in var_map and \"t\" in ds_nc.variables:\n",
    "        zarr_temp = slice_zarr(\"temperature\")\n",
    "        nc_temp   = slice_nc(\"t\")\n",
    "        eq_temp   = (zarr_temp == nc_temp)\n",
    "        eq_arrays.append(eq_temp) \n",
    "        eq_descriptions.append(\"temperature vs t\")\n",
    "\n",
    "    # Compare pressure => p\n",
    "    if \"pressure\" in var_map and \"p\" in ds_nc.variables:\n",
    "        zarr_pres = slice_zarr(\"pressure\")\n",
    "        nc_pres   = slice_nc(\"p\")\n",
    "        eq_pres   = (zarr_pres == nc_pres)\n",
    "        eq_arrays.append(eq_pres)\n",
    "        eq_descriptions.append(\"pressure vs p\")\n",
    "\n",
    "    # Compare energy => e\n",
    "    if \"energy\" in var_map and \"e\" in ds_nc.variables:\n",
    "        zarr_ener = slice_zarr(\"energy\")\n",
    "        nc_ener   = slice_nc(\"e\")\n",
    "        eq_ener   = (zarr_ener == nc_ener)\n",
    "        eq_arrays.append(eq_ener)\n",
    "        eq_descriptions.append(\"energy vs e\")\n",
    "\n",
    "    # Compare velocity => (u, v, w)\n",
    "    if \"velocity\" in var_map and all(comp in ds_nc.variables for comp in [\"u\", \"v\", \"w\"]):\n",
    "        # shape => [time, z, y, x, component=3]\n",
    "        zarr_vel = var_map[\"velocity\"].isel(\n",
    "            time=slice(min(times), max(times)+1),\n",
    "            z=slice(0, z_slice),\n",
    "            y=slice(0, y_slice),\n",
    "            x=slice(0, x_slice),\n",
    "        ).isel(time=times if isinstance(times, list) else range(len(times)))\n",
    "\n",
    "        for comp_idx, comp_name in enumerate([\"u\", \"v\", \"w\"]):\n",
    "            nc_comp = slice_nc(comp_name)  # shape [time, nnz, nny, nnx]\n",
    "            zarr_comp = zarr_vel.isel(component=comp_idx)  # shape [time, z, y, x]\n",
    "            eq_comp = (zarr_comp == nc_comp)\n",
    "            eq_arrays.append(eq_comp)\n",
    "            eq_descriptions.append(f\"velocity[{comp_idx}] vs {comp_name}\")\n",
    "\n",
    "    # If eq_arrays is empty, no matching variables found\n",
    "    if not eq_arrays:\n",
    "        print(\"No matching variables to compare!\")\n",
    "        ds_nc.close()\n",
    "        return\n",
    "\n",
    "    #---------------------\n",
    "    # 4) SINGLE COMPUTE\n",
    "    #---------------------\n",
    "    print(f\"Built {len(eq_arrays)} comparisons. Now computing with Dask (lazy).\")\n",
    "    with ProgressBar():\n",
    "        eq_results = compute(*eq_arrays)\n",
    "        # eq_results is a tuple of bool xarray.DataArray objects.\n",
    "\n",
    "    #---------------------\n",
    "    # 5) REPORT PER TIMESTEP\n",
    "    #---------------------\n",
    "    # Each eq_result => shape [time, z_slice, y_slice, x_slice], boolean\n",
    "    # We'll do a .all(dim=[\"z\",\"y\",\"x\"]) => shape [time], for each eq_result.\n",
    "    # Then print out each time’s True/False. \n",
    "    # If you used different dim names, adapt accordingly.\n",
    "\n",
    "    # Convert `times` to a list to iterate easily\n",
    "    times_list = list(times)  # e.g. [0,1,2,...,104] or some subset\n",
    "    for eq_array, desc in zip(eq_results, eq_descriptions):\n",
    "        # eq_array is an xarray.DataArray of shape [time, z_slice, y_slice, x_slice]\n",
    "        # Do a .all over spatial dims\n",
    "        # If dims are named (\"time\", \"z\", \"y\", \"x\"), we do eq_array.all(dim=[\"z\",\"y\",\"x\"])\n",
    "        # If they’re named differently, adapt.\n",
    "        eq_per_t = eq_array.all(dim=(\"z\",\"y\",\"x\"))\n",
    "\n",
    "        print(f\"\\n=== {desc} ===\")\n",
    "        for i, tval in enumerate(times_list):\n",
    "            is_match = bool(eq_per_t[i].values)  # True/False\n",
    "            print(f\"  t={tval}, match={is_match}\")\n",
    "\n",
    "    ds_nc.close()\n",
    "    print(\"Comparison done. All NetCDF files closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (in a notebook cell):\n",
    "\n",
    "import zarr\n",
    "\n",
    "# 1) Open your Zarr group (raw zarr, not xarray) \n",
    "#    - If you already have xarray.open_zarr(...), that's also fine,\n",
    "#      but the code above expects a zarr.hierarchy.Group for \"zarr_group\".\n",
    "zarr_path = \"/path/to/zarr_data\"\n",
    "jhf_hr_zarr = zarr.open_group(zarr_path, mode='r')\n",
    "\n",
    "# 2) Provide the NetCDF path pattern\n",
    "nc_pattern = \"/path/to/jhf.*.nc\"  \n",
    "# (Assumes jhf.000.nc, jhf.001.nc, ... each containing variables t, p, e, u, v, w)\n",
    "\n",
    "# 3) Choose timesteps and slice sizes\n",
    "times_to_compare = range(0, 105, 5)  # e.g. [0, 5, 10, 15, ..., 100]\n",
    "z_slice_size = 64\n",
    "y_slice_size = 64\n",
    "x_slice_size = 64\n",
    "\n",
    "# 4) Call the function\n",
    "compare_zarr_and_netcdf_allvars(\n",
    "    zarr_group=jhf_hr_zarr,\n",
    "    netcdf_path_pattern=nc_pattern,\n",
    "    times=times_to_compare,\n",
    "    z_slice=z_slice_size,\n",
    "    y_slice=y_slice_size,\n",
    "    x_slice=x_slice_size,\n",
    "    netcdf_chunk=64  # netCDF chunk in nnz, nny, nnx\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
