{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used to sanity-check data: plotting raw and written files, calculating various statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T16:56:09.232582Z",
     "iopub.status.busy": "2025-01-15T16:56:09.232285Z",
     "iopub.status.idle": "2025-01-15T16:56:09.235876Z",
     "shell.execute_reply": "2025-01-15T16:56:09.235273Z",
     "shell.execute_reply.started": "2025-01-15T16:56:09.232557Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_hr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048high/stsabl2048high.zarr\"\n",
    "raw_jhf_hr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.000.nc\"\n",
    "raw_jhf_hr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.001.nc\"\n",
    "raw_jhf_hr_104_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.104.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T16:56:09.336675Z",
     "iopub.status.busy": "2025-01-15T16:56:09.336412Z",
     "iopub.status.idle": "2025-01-15T16:56:21.518135Z",
     "shell.execute_reply": "2025-01-15T16:56:21.517467Z",
     "shell.execute_reply.started": "2025-01-15T16:56:09.336657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "jhf_hr_zarr = zarr.open(stored_jhf_hr_path)\n",
    "jhf_hr_netcdf_t0 = xr.open_dataset(raw_jhf_hr_0_path)\n",
    "jhf_hr_netcdf_t1 = xr.open_dataset(raw_jhf_hr_1_path)\n",
    "jhf_hr_netcdf_t104 = xr.open_dataset(raw_jhf_hr_104_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T16:56:21.519623Z",
     "iopub.status.busy": "2025-01-15T16:56:21.519196Z",
     "iopub.status.idle": "2025-01-15T16:56:31.015177Z",
     "shell.execute_reply": "2025-01-15T16:56:31.014532Z",
     "shell.execute_reply.started": "2025-01-15T16:56:21.519608Z"
    }
   },
   "outputs": [],
   "source": [
    "stored_jhf_lr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048low/stsabl2048low.zarr\"\n",
    "raw_jhf_lr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.000.nc\"\n",
    "raw_jhf_lr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.001.nc\"\n",
    "raw_jhf_lr_19_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.019.nc\"\n",
    "\n",
    "\n",
    "jhf_lr_zarr = zarr.open(stored_jhf_lr_path)\n",
    "jhf_lr_netcdf_t0 = xr.open_dataset(raw_jhf_lr_0_path)\n",
    "jhf_lr_netcdf_t1 = xr.open_dataset(raw_jhf_lr_1_path)\n",
    "jhf_lr_netcdf_t19 = xr.open_dataset(raw_jhf_lr_19_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# JHD (First NCAR dataset) Plot NetCDF Raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw_ncar_folder_path = '/home/idies/workspace/turb/data02_02/ncar-low-rate-fixed-dt/'\n",
    "raw_ncar_folder_path = '/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr'\n",
    "save_folder_path = '/home/idies/workspace/Storage/ariel4/persistent/ncar-zarr-code/zarr_reading/visualizations/'\n",
    "\n",
    "chunk_size=64\n",
    "\n",
    "\n",
    "var = 'e'\n",
    "variable = var\n",
    "\n",
    "# timestep_range = range(5) # This will definitely crash the Kernel\n",
    "timestep_nr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# needed for sciserver jobs\n",
    "%cd /home/idies/workspace/Storage/ariel4/persistent/zarrify-across-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for timestep_nr in timestep_range:\n",
    "#     data = xr.open_dataset(raw_ncar_folder_path + \"/jhd.00\" + str(timestep_nr) + \".nc\")\n",
    "\n",
    "\n",
    "data_xr = xr.open_dataset(raw_ncar_folder_path + \"/jhf.\" + str(timestep_nr).zfill(3) + \".nc\", chunks={'nnz': chunk_size, 'nny': chunk_size, 'nnx': chunk_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "steps = range(0, data_xr['t'].shape[2], 10)\n",
    "\n",
    "# for i, z in enumerate(z_steps):\n",
    "#     print(i,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Read Access Time Results\n",
    "\n",
    "3min 45s +- 4min(!) to load Array `np.array(data[var])`\n",
    "\n",
    "33.3s to plot using in-memory numpy array (from above)\n",
    "\n",
    "14min 17s +- 6min for loading data using `data_xr[var][slice]` every time\n",
    "\n",
    "Skipping the np.array loading takes wayyy too long (>1h for 7 runs atm)\n",
    "\n",
    "<font color=\"red\">Use `np.array(data_xr['e'].isel(nnz=z_indices, nny=slice(None), nnx=slice(None)))`!! Only 15sec!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO make this into a function\n",
    "\n",
    "z_indices = [0]\n",
    "x_indices = [0]\n",
    "# z_indices = [2047]\n",
    "z = 0\n",
    "\n",
    "# Change this to slice along a different axis\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(None), nnx=slice(None)))\n",
    "# Load only 512x512\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(0, 512), nnx=slice(0, 512)))\n",
    "slice_data = np.array(data_xr[var].isel(nnz=slice(0, 512), nny=slice(0, 512), nnx=z_indices))\n",
    "\n",
    "slice_data = np.squeeze(slice_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "slice_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice_data = slice_data[:512, :512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(slice_data)#, cmap='gist_gray')#, vmin=-.5, vmax=.6)\n",
    "\n",
    "#     name = \"[z,y=\" +str(y) + \",x]\" # y\n",
    "# name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z=\" +str(z) + \",y,x]\" # z\n",
    "name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z,y,x=\" +str(z) + \"]\" # x\n",
    "\n",
    "plt.title(name, fontsize=20)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save figures to disk\n",
    "# plt.savefig(f'visualizations/timestep_' + str(timestep_nr) + '/' + var + \"/\" + name + '.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO make this into a function\n",
    "var = 'u'\n",
    "\n",
    "z_indices = [0]\n",
    "x_indices = [0]\n",
    "# z_indices = [2047]\n",
    "z = 0\n",
    "\n",
    "# Change this to slice along a different axis\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(None), nnx=slice(None)))\n",
    "# Load only 512x512\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(0, 512), nnx=slice(0, 512)))\n",
    "slice_data = np.array(data_xr[var].isel(nnz=slice(0, 512), nny=slice(0, 512), nnx=z_indices))\n",
    "\n",
    "slice_data = np.squeeze(slice_data)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(slice_data)#, cmap='gist_gray')#, vmin=-.5, vmax=.6)\n",
    "\n",
    "#     name = \"[z,y=\" +str(y) + \",x]\" # y\n",
    "# name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z=\" +str(z) + \",y,x]\" # z\n",
    "name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z,y,x=\" +str(z) + \"]\" # x\n",
    "\n",
    "plt.title(name, fontsize=20)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save figures to disk\n",
    "# plt.savefig(f'visualizations/timestep_' + str(timestep_nr) + '/' + var + \"/\" + name + '.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO make this into a function\n",
    "var = 'v'\n",
    "\n",
    "z_indices = [0]\n",
    "x_indices = [0]\n",
    "# z_indices = [2047]\n",
    "z = 0\n",
    "\n",
    "# Change this to slice along a different axis\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(None), nnx=slice(None)))\n",
    "# Load only 512x512\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(0, 512), nnx=slice(0, 512)))\n",
    "slice_data = np.array(data_xr[var].isel(nnz=slice(0, 512), nny=slice(0, 512), nnx=z_indices))\n",
    "\n",
    "slice_data = np.squeeze(slice_data)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(slice_data)#, cmap='gist_gray')#, vmin=-.5, vmax=.6)\n",
    "\n",
    "#     name = \"[z,y=\" +str(y) + \",x]\" # y\n",
    "# name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z=\" +str(z) + \",y,x]\" # z\n",
    "name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z,y,x=\" +str(z) + \"]\" # x\n",
    "\n",
    "plt.title(name, fontsize=20)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save figures to disk\n",
    "# plt.savefig(f'visualizations/timestep_' + str(timestep_nr) + '/' + var + \"/\" + name + '.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO make this into a function\n",
    "var = 'w'\n",
    "\n",
    "z_indices = [0]\n",
    "x_indices = [0]\n",
    "# z_indices = [2047]\n",
    "z = 0\n",
    "\n",
    "# Change this to slice along a different axis\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(None), nnx=slice(None)))\n",
    "# Load only 512x512\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(0, 512), nnx=slice(0, 512)))\n",
    "slice_data = np.array(data_xr[var].isel(nnz=slice(0, 512), nny=slice(0, 512), nnx=z_indices))\n",
    "\n",
    "slice_data = np.squeeze(slice_data)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(slice_data)#, cmap='gist_gray')#, vmin=-.5, vmax=.6)\n",
    "\n",
    "#     name = \"[z,y=\" +str(y) + \",x]\" # y\n",
    "# name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z=\" +str(z) + \",y,x]\" # z\n",
    "name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z,y,x=\" +str(z) + \"]\" # x\n",
    "\n",
    "plt.title(name, fontsize=20)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save figures to disk\n",
    "# plt.savefig(f'visualizations/timestep_' + str(timestep_nr) + '/' + var + \"/\" + name + '.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make this into a function\n",
    "var = 't'\n",
    "\n",
    "z_indices = [0]\n",
    "x_indices = [0]\n",
    "# z_indices = [2047]\n",
    "z = 0\n",
    "\n",
    "# Change this to slice along a different axis\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(None), nnx=slice(None)))\n",
    "# Load only 512x512\n",
    "# slice_data = np.array(data_xr[var].isel(nnz=z_indices, nny=slice(0, 512), nnx=slice(0, 512)))\n",
    "slice_data = np.array(data_xr[var].isel(nnz=slice(0, 512), nny=slice(0, 512), nnx=z_indices))\n",
    "\n",
    "slice_data = np.squeeze(slice_data)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(slice_data)#, cmap='gist_gray')#, vmin=-.5, vmax=.6)\n",
    "\n",
    "#     name = \"[z,y=\" +str(y) + \",x]\" # y\n",
    "# name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z=\" +str(z) + \",y,x]\" # z\n",
    "name = \"Timestep = \", timestep_nr, \", Var = \", var, \"[z,y,x=\" +str(z) + \"]\" # x\n",
    "\n",
    "plt.title(name, fontsize=20)\n",
    "plt.colorbar()\n",
    "\n",
    "# Save figures to disk\n",
    "# plt.savefig(f'visualizations/timestep_' + str(timestep_nr) + '/' + var + \"/\" + name + '.png')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>\n",
    "\n",
    "## Remember, index is nnz-nny-nnx. first dim is Z\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Quick-Verify Correctness of data\n",
    "\n",
    "1. Check if `data == 0`\n",
    "\n",
    "2. Pick one $64^3$ chunk and compare it to raw NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### `zarr.info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['velocity'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Indexing, Compare to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Checking whether field all zeros - True is bad!\")\n",
    "\n",
    "for t in range(105):\n",
    "    print(\"t=\", t, \" - \", np.all(jhf_hr_zarr['temperature'][t,:64,:64,:64,0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][1,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-01-15T14:50:41.857673Z",
     "shell.execute_reply": "2025-01-15T14:50:41.857091Z",
     "shell.execute_reply.started": "2025-01-15T14:44:20.357009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  97 True\n",
      "t:  98 True\n",
      "t:  99 True\n",
      "t:  100 True\n",
      "t:  101 True\n",
      "t:  102 True\n",
      "t:  103 True\n",
      "t:  104 True\n"
     ]
    }
   ],
   "source": [
    "for t in range(93, 105):\n",
    "    zarr_comparison_data = jhf_hr_zarr['temperature'][t,:64,:64,:64,0]\n",
    "\n",
    "    raw_t_path = f\"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.{t:03d}.nc\"\n",
    "    raw_xr = xr.open_dataset(raw_t_path)\n",
    "    raw_t = raw_xr['t'].isel(nnx=slice(0, 64), nny=slice(0, 64), nnz=slice(0, 64)).values\n",
    "    \n",
    "    print(\"t: \", t, np.all(zarr_comparison_data == raw_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,0,0,:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_hr_netcdf_t0['e'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Xarray complains about missing metadata. NOT Fixed by GPT o1\n",
    "\n",
    "`written_ds_xr = xr.open_dataset(stored_jhf_path, engine='zarr', consolidated=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][0, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['energy'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_lr_netcdf_t0['t'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Efficient Zarr full data Slices\n",
    "\n",
    "This can take a few minutes\n",
    "\n",
    " Sciserver doesn't allow localhost connections, so can't use Dask Cluster console Sciserver doesn't allow localhost connections, so can't use Dask Cluster console\n",
    " \n",
    "<font color=\"green\"> Lazy loading speeds up reading times 10x+</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T16:55:34.043350Z",
     "iopub.status.busy": "2025-01-15T16:55:34.042408Z",
     "iopub.status.idle": "2025-01-15T16:55:34.655864Z",
     "shell.execute_reply": "2025-01-15T16:55:34.655131Z",
     "shell.execute_reply.started": "2025-01-15T16:55:34.043289Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "def process_zarr(stored_jhf_path, dataset):\n",
    "    if dataset not in ['hr', 'lr']:\n",
    "        raise ValueError(\"Dataset must be 'hr' or 'lr'.\")\n",
    "\n",
    "    store = zarr.open_group(stored_jhf_path, mode='r')\n",
    "\n",
    "    # Create Dask arrays for lazy loading\n",
    "    data_arrays = {}\n",
    "    variables = list(store.array_keys())\n",
    "    for var_name in variables:\n",
    "        zarr_array = store[var_name]\n",
    "        dask_array = da.from_zarr(zarr_array)\n",
    "        # Squeeze scalar variables\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)\n",
    "        data_arrays[var_name] = dask_array\n",
    "\n",
    "    # Function to collect data slices lazily\n",
    "    def collect_data_slices(data_arrays, variables, timesteps):\n",
    "        data_slices = []\n",
    "        titles = []\n",
    "        \n",
    "        for variable in variables:\n",
    "            for timestep in timesteps:\n",
    "                dask_array = data_arrays[variable]\n",
    "                \n",
    "                # Get slices along each dimension (assuming shape = [time, Z, Y, X] or similar)\n",
    "                x_slice = dask_array[timestep, :, :, 0]\n",
    "                y_slice = dask_array[timestep, :, 0, :]\n",
    "                z_slice = dask_array[timestep, 0, :, :]\n",
    "                \n",
    "                # For vector variables, handle components\n",
    "                if variable == 'velocity':\n",
    "                    for component in range(3):\n",
    "                        x_comp_slice = x_slice[..., component]\n",
    "                        y_comp_slice = y_slice[..., component]\n",
    "                        z_comp_slice = z_slice[..., component]\n",
    "                        \n",
    "                        data_slices.extend([x_comp_slice, y_comp_slice, z_comp_slice])\n",
    "                        titles.extend([\n",
    "                            f\"{variable} (component {component}) nnx=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nny=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nnz=0 Timestep={timestep}\"\n",
    "                        ])\n",
    "                else:\n",
    "                    data_slices.extend([x_slice, y_slice, z_slice])\n",
    "                    titles.extend([\n",
    "                        f\"{variable} nnx=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nny=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nnz=0 Timestep={timestep}\"\n",
    "                    ])\n",
    "        return data_slices, titles\n",
    "\n",
    "    # Choose timesteps: here every 5th until the end\n",
    "    timesteps = range(0, data_arrays['energy'].shape[0], 5)\n",
    "\n",
    "    # Collect data slices\n",
    "    data_slices, titles = collect_data_slices(data_arrays, ['energy', 'temperature', 'pressure', 'velocity'], timesteps)\n",
    "\n",
    "    # Compute all data slices at once (lazy -> single compute call)\n",
    "    with ProgressBar():\n",
    "        computed_slices = compute(*data_slices)\n",
    "\n",
    "    # Plot (and now save) all images\n",
    "    # Create a master folder for all slices\n",
    "    master_folder = os.path.join(\"zarr_slices\", dataset)\n",
    "    os.makedirs(master_folder, exist_ok=True)\n",
    "\n",
    "    idx = 0\n",
    "    for variable in ['energy', 'temperature', 'pressure', 'velocity']:\n",
    "        # Make a folder per variable\n",
    "        var_folder = os.path.join(master_folder, variable)\n",
    "        os.makedirs(var_folder, exist_ok=True)\n",
    "        \n",
    "        # We'll have 3 slices per timestep if scalar,\n",
    "        # or 9 slices per timestep if velocity (3 components * 3 slices).\n",
    "        # So we figure out how many slices belong to each variable:\n",
    "        if variable == 'velocity':\n",
    "            slices_per_timestep = 9\n",
    "        else:\n",
    "            slices_per_timestep = 3\n",
    "        \n",
    "        for timestep in timesteps:\n",
    "            # For velocity, we handle 9 images; for others, 3.\n",
    "            subset = computed_slices[idx : idx + slices_per_timestep]\n",
    "            subset_titles = titles[idx : idx + slices_per_timestep]\n",
    "            \n",
    "            for data_slice, title in zip(subset, subset_titles):\n",
    "                plt.figure()\n",
    "                plt.imshow(data_slice)\n",
    "                plt.title(title)\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.colorbar()\n",
    "                \n",
    "                # Create a filename for saving\n",
    "                safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                filename = os.path.join(var_folder, f\"{safe_title}.png\")\n",
    "                plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            \n",
    "            idx += slices_per_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T16:56:31.016618Z",
     "iopub.status.busy": "2025-01-15T16:56:31.016466Z",
     "iopub.status.idle": "2025-01-15T16:58:55.930426Z",
     "shell.execute_reply": "2025-01-15T16:58:55.929516Z",
     "shell.execute_reply.started": "2025-01-15T16:56:31.016604Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 94.95 s\n"
     ]
    }
   ],
   "source": [
    "process_zarr(stored_jhf_lr_path, \"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data Statistics - Mean Temp. across Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T16:31:21.242645Z",
     "iopub.status.busy": "2025-01-15T16:31:21.241570Z",
     "iopub.status.idle": "2025-01-15T16:31:21.250823Z",
     "shell.execute_reply": "2025-01-15T16:31:21.250264Z",
     "shell.execute_reply.started": "2025-01-15T16:31:21.242622Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "from matplotlib import pyplot as plt\n",
    "import dask.array as da\n",
    "\n",
    "def plot_mean_temp_across_z(\n",
    "    ds, \n",
    "    t: int, \n",
    "    data_type: Literal[\"zarr\", \"original\"],\n",
    "    spacing: int = 128  # Loads 1 every 2 chunks; chunks are typically 64^3\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the mean temperature along Z for a given timestep t.\n",
    "    Saves a PNG in the folder 'mean_temperature_plots'.\n",
    "    \n",
    "    ds: dictionary-like, with ds['temperature'] returning either:\n",
    "        - a Dask array (if data_type='zarr'), or\n",
    "        - a NumPy array (if data_type='original').\n",
    "    t: the time index to plot.\n",
    "    data_type: either 'zarr' or 'original', used for logic on lazy compute.\n",
    "    spacing: step size for Z slices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Validate data_type\n",
    "    if data_type not in (\"zarr\", \"original\"):\n",
    "        raise ValueError(\"data_type must be either 'zarr' or 'original'\")\n",
    "    \n",
    "    # Ensure the folder exists\n",
    "    output_folder = \"mean_temperature_plots\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # We want to plot the mean across X and Y for each Z in [0, shape[1], spacing]\n",
    "    z_indices = range(0, ds['temperature'].shape[1], spacing)\n",
    "\n",
    "    if data_type == \"zarr\":\n",
    "        # ds['temperature'] is presumably a Dask array of shape [time, z, y, x, (component?)]\n",
    "        # We'll assume T=..., then the last dimension might be 1 or more. If 1, we can squeeze it.\n",
    "        # Example: ds['temperature'][t, :, :, :, 0] -> [z, y, x] shape\n",
    "        temp_slice = ds['temperature'][t, :, :, :, 0]\n",
    "        \n",
    "        # Take only the z_indices we care about, then mean over x,y\n",
    "        # This is all lazy (no real computation yet).\n",
    "        temp_sliced = temp_slice[list(z_indices), :, :]  # shape [len(z_indices), y, x]\n",
    "        \n",
    "        # Mean over x and y for each z\n",
    "        # shape becomes [len(z_indices)]\n",
    "        z_means = temp_sliced.mean(axis=(1, 2))\n",
    "        \n",
    "        # Trigger actual computation once\n",
    "        xy_means = z_means.compute()\n",
    "    else:\n",
    "        # Original approach: (but still might be slow if it's truly large NumPy arrays)\n",
    "        # We'll do the loop, but you *could* also vectorize if it's a real NumPy array\n",
    "        xy_means = []\n",
    "        for i in z_indices:\n",
    "            xy_means.append(ds['temperature'][t, i, :, :, 0].mean())\n",
    "\n",
    "    # Plotting\n",
    "    plt.plot(list(z_indices), xy_means, marker='o')\n",
    "    plt.title(f\"Mean Temperature across Z (t={t}, data_type={data_type})\")\n",
    "    plt.xlabel(\"Slice (Z)\")\n",
    "    plt.ylabel(\"Average Temperature\")\n",
    "\n",
    "    # File name generation\n",
    "    file_name = os.path.join(output_folder, f\"mean_z_temperature_{data_type}_t_{t}.png\")\n",
    "    plt.savefig(file_name, dpi=150, bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to free up memory\n",
    "    print(f\"Saved plot as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T14:52:01.008364Z",
     "iopub.status.busy": "2025-01-15T14:52:01.008129Z",
     "iopub.status.idle": "2025-01-15T14:52:01.017041Z",
     "shell.execute_reply": "2025-01-15T14:52:01.016582Z",
     "shell.execute_reply.started": "2025-01-15T14:52:01.008348Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zarr.core.Array '/temperature' (105, 2048, 2048, 2048, 1) float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jhf_hr_zarr['temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T14:52:10.034639Z",
     "iopub.status.busy": "2025-01-15T14:52:10.034396Z",
     "iopub.status.idle": "2025-01-15T14:52:10.037884Z",
     "shell.execute_reply": "2025-01-15T14:52:10.037313Z",
     "shell.execute_reply.started": "2025-01-15T14:52:10.034623Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = jhf_hr_zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Across Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T16:31:33.372858Z",
     "iopub.status.busy": "2025-01-15T16:31:33.372529Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppose ds is your dictionary with a Dask array for 'temperature'.\n",
    "timesteps = range(0, ds['temperature'].shape[0], 5)\n",
    "for t in timesteps:\n",
    "    plot_mean_temp_across_z(ds, t, data_type=\"zarr\", spacing=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-15T14:53:23.702012Z",
     "iopub.status.idle": "2025-01-15T14:53:23.702232Z",
     "shell.execute_reply": "2025-01-15T14:53:23.702126Z",
     "shell.execute_reply.started": "2025-01-15T14:53:23.702117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xy_means_original = []\n",
    "\n",
    "for i in range(0, 2048, 50):\n",
    "    xy_means_original.append(original_ds['t'][i,:,:].mean())\n",
    "\n",
    "plt.plot(list(range(0, ds['temperature'].shape[1], 50)), xy_means_original)\n",
    "\n",
    "plt.title(\"Temperature across Z\")\n",
    "plt.xlabel(\"Slice (Z)\")\n",
    "plt.ylabel(\"Average Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yz_means = []\n",
    "\n",
    "\n",
    "for i in range(0, 2048, 50):\n",
    "    yz_means.append(ds['temperature'][0,:,:,i,0].mean())\n",
    "\n",
    "\n",
    "plt.plot(list(range(0, 2048, 50)), yz_means)\n",
    "plt.title(\"Temperature across X\")\n",
    "plt.xlabel(\"Slice (X)\")\n",
    "plt.ylabel(\"Average Temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yz_means_original = []\n",
    "\n",
    "for i in range(0, 2048, 50):\n",
    "    yz_means_original.append(original_ds['t'][:,:,i].mean())\n",
    "\n",
    "\n",
    "plt.plot(list(range(0, 2048, 50)), yz_means_original)\n",
    "plt.title(\"Temperature across X\")\n",
    "plt.xlabel(\"Slice (X)\")\n",
    "plt.ylabel(\"Average Temperature\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
