{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used to sanity-check data: plotting raw and written files, calculating various statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:14.394034Z",
     "iopub.status.busy": "2025-01-15T20:31:14.393421Z",
     "iopub.status.idle": "2025-01-15T20:31:15.405491Z",
     "shell.execute_reply": "2025-01-15T20:31:15.404805Z",
     "shell.execute_reply.started": "2025-01-15T20:31:14.393962Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:15.407062Z",
     "iopub.status.busy": "2025-01-15T20:31:15.406656Z",
     "iopub.status.idle": "2025-01-15T20:31:15.410059Z",
     "shell.execute_reply": "2025-01-15T20:31:15.409600Z",
     "shell.execute_reply.started": "2025-01-15T20:31:15.407042Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_hr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048high/stsabl2048high.zarr\"\n",
    "raw_jhf_hr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.000.nc\"\n",
    "raw_jhf_hr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.001.nc\"\n",
    "raw_jhf_hr_104_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.104.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:15.410823Z",
     "iopub.status.busy": "2025-01-15T20:31:15.410676Z",
     "iopub.status.idle": "2025-01-15T20:31:15.483014Z",
     "shell.execute_reply": "2025-01-15T20:31:15.482366Z",
     "shell.execute_reply.started": "2025-01-15T20:31:15.410811Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr = zarr.open(stored_jhf_hr_path)\n",
    "jhf_hr_netcdf_t0 = xr.open_dataset(raw_jhf_hr_0_path)\n",
    "jhf_hr_netcdf_t1 = xr.open_dataset(raw_jhf_hr_1_path)\n",
    "jhf_hr_netcdf_t104 = xr.open_dataset(raw_jhf_hr_104_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:15.484379Z",
     "iopub.status.busy": "2025-01-15T20:31:15.484221Z",
     "iopub.status.idle": "2025-01-15T20:31:15.517448Z",
     "shell.execute_reply": "2025-01-15T20:31:15.516827Z",
     "shell.execute_reply.started": "2025-01-15T20:31:15.484364Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_lr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048low/stsabl2048low.zarr\"\n",
    "raw_jhf_lr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.000.nc\"\n",
    "raw_jhf_lr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.001.nc\"\n",
    "raw_jhf_lr_19_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.019.nc\"\n",
    "\n",
    "\n",
    "jhf_lr_zarr = zarr.open(stored_jhf_lr_path)\n",
    "jhf_lr_netcdf_t0 = xr.open_dataset(raw_jhf_lr_0_path)\n",
    "jhf_lr_netcdf_t1 = xr.open_dataset(raw_jhf_lr_1_path)\n",
    "jhf_lr_netcdf_t19 = xr.open_dataset(raw_jhf_lr_19_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"cyan\">\n",
    "\n",
    "# Remember, data is saved in `nnz-nny-nnx`\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Quick-Verify Correctness of data\n",
    "\n",
    "1. Check if `data == 0`\n",
    "\n",
    "2. Pick one $64^3$ chunk and compare it to raw NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### `zarr.info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['velocity'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Indexing, Compare to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Checking whether field all zeros - True is bad!\")\n",
    "\n",
    "for t in range(105):\n",
    "    print(\"t=\", t, \" - \", np.all(jhf_hr_zarr['temperature'][t,:64,:64,:64,0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][1,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-01-15T14:50:41.857673Z",
     "shell.execute_reply": "2025-01-15T14:50:41.857091Z",
     "shell.execute_reply.started": "2025-01-15T14:44:20.357009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  97 True\n",
      "t:  98 True\n",
      "t:  99 True\n",
      "t:  100 True\n",
      "t:  101 True\n",
      "t:  102 True\n",
      "t:  103 True\n",
      "t:  104 True\n"
     ]
    }
   ],
   "source": [
    "for t in range(93, 105):\n",
    "    zarr_comparison_data = jhf_hr_zarr['temperature'][t,:64,:64,:64,0]\n",
    "\n",
    "    raw_t_path = f\"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.{t:03d}.nc\"\n",
    "    raw_xr = xr.open_dataset(raw_t_path)\n",
    "    raw_t = raw_xr['t'].isel(nnx=slice(0, 64), nny=slice(0, 64), nnz=slice(0, 64)).values\n",
    "    \n",
    "    print(\"t: \", t, np.all(zarr_comparison_data == raw_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,0,0,:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_hr_netcdf_t0['e'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Xarray complains about missing metadata. NOT Fixed by GPT o1\n",
    "\n",
    "`written_ds_xr = xr.open_dataset(stored_jhf_path, engine='zarr', consolidated=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][0, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['energy'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_lr_netcdf_t0['t'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Efficient Zarr full data Slices\n",
    "\n",
    "This can take a few minutes\n",
    "\n",
    " Sciserver doesn't allow localhost connections, so can't use Dask Cluster console Sciserver doesn't allow localhost connections, so can't use Dask Cluster console\n",
    " \n",
    "<font color=\"green\"> Lazy loading speeds up reading times 10x+</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T17:36:10.638762Z",
     "iopub.status.busy": "2025-01-15T17:36:10.638516Z",
     "iopub.status.idle": "2025-01-15T17:36:10.651136Z",
     "shell.execute_reply": "2025-01-15T17:36:10.650513Z",
     "shell.execute_reply.started": "2025-01-15T17:36:10.638744Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "def process_zarr(stored_jhf_path, dataset):\n",
    "    if dataset not in ['hr', 'lr']:\n",
    "        raise ValueError(\"Dataset must be 'hr' or 'lr'.\")\n",
    "\n",
    "    # Open the Zarr group\n",
    "    store = zarr.open_group(stored_jhf_path, mode='r')\n",
    "\n",
    "    # Create Dask arrays\n",
    "    data_arrays = {}\n",
    "    variables = list(store.array_keys())\n",
    "    for var_name in variables:\n",
    "        zarr_array = store[var_name]\n",
    "        dask_array = da.from_zarr(zarr_array)\n",
    "        # Squeeze scalar variables\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)\n",
    "        data_arrays[var_name] = dask_array\n",
    "\n",
    "    # Function to collect data slices\n",
    "    def collect_data_slices(data_arrays, variables, timesteps):\n",
    "        data_slices = []\n",
    "        titles = []\n",
    "        \n",
    "        for variable in variables:\n",
    "            for timestep in timesteps:\n",
    "                dask_array = data_arrays[variable]\n",
    "                \n",
    "                # Get slices along each dimension (assuming shape = [time, Z, Y, X] or similar)\n",
    "                x_slice = dask_array[timestep, :, :, 0]\n",
    "                y_slice = dask_array[timestep, :, 0, :]\n",
    "                z_slice = dask_array[timestep, 0, :, :]\n",
    "                \n",
    "                # For vector variables, handle components\n",
    "                if variable == 'velocity':\n",
    "                    for component in range(3):\n",
    "                        x_comp_slice = x_slice[..., component]\n",
    "                        y_comp_slice = y_slice[..., component]\n",
    "                        z_comp_slice = z_slice[..., component]\n",
    "                        \n",
    "                        data_slices.extend([x_comp_slice, y_comp_slice, z_comp_slice])\n",
    "                        titles.extend([\n",
    "                            f\"{variable} (component {component}) nnx=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nny=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nnz=0 Timestep={timestep}\"\n",
    "                        ])\n",
    "                else:\n",
    "                    data_slices.extend([x_slice, y_slice, z_slice])\n",
    "                    titles.extend([\n",
    "                        f\"{variable} nnx=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nny=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nnz=0 Timestep={timestep}\"\n",
    "                    ])\n",
    "        return data_slices, titles\n",
    "\n",
    "    # Choose timesteps: here every 5th until the end\n",
    "    timesteps = range(0, data_arrays['energy'].shape[0], 5)  \n",
    "\n",
    "    # Collect data slices\n",
    "    data_slices, titles = collect_data_slices(data_arrays, ['energy', 'temperature', 'pressure', 'velocity'], timesteps)\n",
    "\n",
    "    # Compute all data slices at once (lazy -> single compute call)\n",
    "    with ProgressBar():\n",
    "        computed_slices = compute(*data_slices)\n",
    "\n",
    "    # Plot (and now save) all images\n",
    "    # Create a master folder for all slices\n",
    "    master_folder = os.path.join(\"zarr_slices\", dataset)\n",
    "    os.makedirs(master_folder, exist_ok=True)\n",
    "\n",
    "    idx = 0\n",
    "    for variable in ['energy', 'temperature', 'pressure', 'velocity']:\n",
    "        # Make a folder per variable\n",
    "        var_folder = os.path.join(master_folder, variable)\n",
    "        os.makedirs(var_folder, exist_ok=True)\n",
    "        \n",
    "        # We'll have 3 slices per timestep if scalar,\n",
    "        # or 9 slices per timestep if velocity (3 components * 3 slices).\n",
    "        # So we figure out how many slices belong to each variable:\n",
    "        if variable == 'velocity':\n",
    "            slices_per_timestep = 9\n",
    "        else:\n",
    "            slices_per_timestep = 3\n",
    "        \n",
    "        for timestep in timesteps:\n",
    "            # For velocity, we handle 9 images; for others, 3.\n",
    "            subset = computed_slices[idx : idx + slices_per_timestep]\n",
    "            subset_titles = titles[idx : idx + slices_per_timestep]\n",
    "            \n",
    "            for data_slice, title in zip(subset, subset_titles):\n",
    "                plt.figure()\n",
    "                plt.imshow(data_slice)\n",
    "                plt.title(title)\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.colorbar()\n",
    "                \n",
    "                # Create a filename for saving\n",
    "                safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                filename = os.path.join(var_folder, f\"Timestep_{timestep}_{safe_title}.png\")\n",
    "                plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            \n",
    "            idx += slices_per_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T17:36:10.779513Z",
     "iopub.status.busy": "2025-01-15T17:36:10.779371Z",
     "iopub.status.idle": "2025-01-15T17:37:53.271401Z",
     "shell.execute_reply": "2025-01-15T17:37:53.270752Z",
     "shell.execute_reply.started": "2025-01-15T17:36:10.779500Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 52.64 s\n"
     ]
    }
   ],
   "source": [
    "process_zarr(stored_jhf_lr_path, \"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Statistics - Mean Temp. across Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:18.812838Z",
     "iopub.status.busy": "2025-01-15T20:31:18.812595Z",
     "iopub.status.idle": "2025-01-15T20:31:18.828959Z",
     "shell.execute_reply": "2025-01-15T20:31:18.828385Z",
     "shell.execute_reply.started": "2025-01-15T20:31:18.812823Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.array as da\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_slices_and_mean_z(\n",
    "    ds_zarr_group, \n",
    "    variables, \n",
    "    time_start=0, \n",
    "    time_stop=105, \n",
    "    time_step=5, \n",
    "    z_step=128,\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Creates a Dask array for each variable from the Zarr group ds_zarr_group.\n",
    "    2) Gathers slice arrays (X=0, Y=0, Z=0) for each variable/time.\n",
    "    3) Gathers the mean-temp-across-Z (every z_step along Z).\n",
    "    4) Performs exactly one .compute() to load everything.\n",
    "    5) Plots and saves images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_zarr_group : zarr.hierarchy.Group\n",
    "        A Zarr group, e.g. from zarr.open_group(...), with arrays named by `variables`.\n",
    "        Each array shape typically [time, z, y, x, 1 or 3].\n",
    "    variables : list of str\n",
    "        E.g. [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "    time_start, time_stop, time_step : int\n",
    "        We will process times in range(time_start, time_stop, time_step).\n",
    "        Make sure time_stop <= ds['temperature'].shape[0].\n",
    "    z_step : int\n",
    "        Step size along Z dimension for the mean calculation (and plot).\n",
    "    \"\"\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Convert each Zarr array to a Dask array (lazy)\n",
    "    #    ds_zarr_group[var] is a zarr Array; we want da.Array for each var\n",
    "    # -------------------------------------------------------------------------\n",
    "    data_arrays = {}\n",
    "    for var in variables:\n",
    "        zarr_array = ds_zarr_group[var]  # shape e.g. (105, 2048, 2048, 2048, 1)\n",
    "        dask_array = da.from_zarr(zarr_array)  # now a Dask array, fully lazy\n",
    "        # If last dim == 1, squeeze it out\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)  # shape => (time, z, y, x)\n",
    "        data_arrays[var] = dask_array\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Build a range of timesteps as slice objects (NOT a for-loop yet)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll do time slicing using slice(time_start, time_stop, time_step).\n",
    "    # For example, if time_start=0, time_stop=105, time_step=5 => times = 0..100\n",
    "    # This is a single slice if you want standard 0,5,10,... indexing.\n",
    "    # But if you truly need [0, 5, 10, ...], that's still a step slice.\n",
    "    # NOTE: This requires that time_stop < shape[0]. E.g. shape[0]=105 => last valid index=104\n",
    "    time_slice = slice(time_start, time_stop, time_step)\n",
    "    # We'll confirm that time_stop <= data_arrays[any_var].shape[0]\n",
    "    # but let's assume user does that.\n",
    "\n",
    "    # We'll also define z-slice for the mean. E.g. z_slice = slice(None, None, z_step)\n",
    "    # i.e. every z_step along that axis\n",
    "    z_slice = slice(None, None, z_step)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3a) Gather the Dask slice arrays for X=0, Y=0, Z=0\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll store them in lists along with their eventual plot titles\n",
    "    slice_arrays = []\n",
    "    slice_titles = []\n",
    "\n",
    "    for var in variables:\n",
    "        arr = data_arrays[var]  # shape e.g. [time, z, y, x] (for scalars) or [time, z, y, x, 3] (if not squeezed)\n",
    "        # We'll do a standard shape: (time, z, y, x) for scalars\n",
    "        # For velocity, we do shape => (time, z, y, x, 3). If you have that, you'd handle differently.\n",
    "\n",
    "        # We'll produce these slices for the times in time_slice (i.e. arr[time_slice, ...]):\n",
    "        #   x=0 => arr[:, :, :, 0]\n",
    "        #   y=0 => arr[:, :, 0, :]\n",
    "        #   z=0 => arr[:, 0, :, :]\n",
    "        # But we still want to only pick the times in [time_slice].\n",
    "        # So for each slice, we do e.g. arr[time_slice, :, :, 0].\n",
    "        # We'll keep them as separate arrays.\n",
    "\n",
    "        # If it's \"velocity\" and has shape [time, z, y, x, 3], do 3 components\n",
    "        if var == \"velocity\" and arr.ndim == 5:\n",
    "            # arr.shape => (time, z, y, x, 3)\n",
    "            # We want x=0 => arr[time_slice, :, :, 0, comp]\n",
    "            # Similarly y=0 => arr[time_slice, :, 0, :, comp]\n",
    "            # etc. We'll build 3 slices for each comp\n",
    "            for comp in range(3):\n",
    "                # x=0\n",
    "                vx0 = arr[time_slice, :, :, 0, comp]\n",
    "                slice_arrays.append(vx0)\n",
    "                slice_titles.append(f\"{var} (component {comp}) x=0\")\n",
    "\n",
    "                # y=0\n",
    "                vy0 = arr[time_slice, :, 0, :, comp]\n",
    "                slice_arrays.append(vy0)\n",
    "                slice_titles.append(f\"{var} (component {comp}) y=0\")\n",
    "\n",
    "                # z=0\n",
    "                vz0 = arr[time_slice, 0, :, :, comp]\n",
    "                slice_arrays.append(vz0)\n",
    "                slice_titles.append(f\"{var} (component {comp}) z=0\")\n",
    "\n",
    "        else:\n",
    "            # Scalar variable shape => (time, z, y, x)\n",
    "            # x=0\n",
    "            x0 = arr[time_slice, :, :, 0]\n",
    "            slice_arrays.append(x0)\n",
    "            slice_titles.append(f\"{var} x=0\")\n",
    "\n",
    "            # y=0\n",
    "            y0 = arr[time_slice, :, 0, :]\n",
    "            slice_arrays.append(y0)\n",
    "            slice_titles.append(f\"{var} y=0\")\n",
    "\n",
    "            # z=0\n",
    "            z0 = arr[time_slice, 0, :, :]\n",
    "            slice_arrays.append(z0)\n",
    "            slice_titles.append(f\"{var} z=0\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3b) Gather the Dask array for \"mean temperature across Z\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll only do this for the \"temperature\" variable if it exists\n",
    "    mean_temp_dask = None\n",
    "    if \"temperature\" in data_arrays:\n",
    "        temp_arr = data_arrays[\"temperature\"]  # shape [time, z, y, x]\n",
    "        # We'll slice time => [time_slice], and z => [::z_step], then mean over (y,x).\n",
    "        # But if we do a step for z, we can do e.g. temp_arr[time_slice, ::z_step, :, :]\n",
    "        # That is standard slicing (no list-of-indices).\n",
    "        # Then .mean(axis=[2,3]) => shape: [num_times, number_of_z_samples]\n",
    "        stepped = temp_arr[time_slice, z_slice, :, :]\n",
    "        mean_temp_dask = stepped.mean(axis=(2, 3))  # shape => [num_times, # of z_slices]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Single .compute() for all\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll combine all slice arrays + mean_temp_dask into one big list\n",
    "    # and do exactly one .compute().\n",
    "    to_compute = []\n",
    "    to_compute.extend(slice_arrays)  # each is a Dask array of shape [num_times, ...]\n",
    "    if mean_temp_dask is not None:\n",
    "        to_compute.append(mean_temp_dask)\n",
    "\n",
    "    # If there's nothing to compute, just return\n",
    "    if not to_compute:\n",
    "        print(\"No data to compute. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Building Dask graph. No data is read yet. Now calling .compute() with a ProgressBar...\")\n",
    "    os.makedirs(master_slice_folder, exist_ok=True)\n",
    "    os.makedirs(mean_output_folder, exist_ok=True)\n",
    "\n",
    "    with ProgressBar():\n",
    "        results = compute(*to_compute)\n",
    "\n",
    "    # results is a tuple of length = len(to_compute).\n",
    "    # The first len(slice_arrays) items are the slice results,\n",
    "    # the last item (if present) is mean_temp_dask.\n",
    "\n",
    "    slice_results = results[:len(slice_arrays)]\n",
    "    mean_results = results[-1] if mean_temp_dask is not None else None\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Plot the slice results\n",
    "    #    - Each slice result is shape [num_times, ...], so we must loop\n",
    "    #      over the timesteps to produce separate images.\n",
    "    # -------------------------------------------------------------------------\n",
    "    times = list(range(time_start, time_stop, time_step))  # e.g. [0,5,10,...]\n",
    "\n",
    "    idx = 0\n",
    "    for slice_result, title in zip(slice_results, slice_titles):\n",
    "        # slice_result shape => [num_times, z, y?], depends if x=0 vs y=0 vs z=0\n",
    "        # We want one image per time. So if slice_result.shape[0] is # of timesteps,\n",
    "        # we do a for-loop:\n",
    "        for i, t in enumerate(times):\n",
    "            single_time_slice = slice_result[i]  # shape => e.g. [z, y], etc.\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(single_time_slice)\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.colorbar()\n",
    "            plt.title(f\"{title}, t={t}\")\n",
    "\n",
    "            safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "            fname = os.path.join(master_slice_folder, f\"{safe_title}_t_{t}.png\")\n",
    "            plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Plot the mean temperature results\n",
    "    # -------------------------------------------------------------------------\n",
    "    if mean_results is not None:\n",
    "        # shape => [num_times, # of z_slices]\n",
    "        # We'll plot each row\n",
    "        # The z_slices are from z=0..2048..z_step, so let's build that list\n",
    "        z_indices_list = list(range(0, data_arrays[\"temperature\"].shape[1], z_step))\n",
    "        for i, t in enumerate(times):\n",
    "            row = mean_results[i, :]  # shape [# of z_slices]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(z_indices_list, row, marker='o')\n",
    "            plt.title(f\"Mean Temperature across Z (t={t})\")\n",
    "            plt.xlabel(\"Z index\")\n",
    "            plt.ylabel(\"Avg Temp\")\n",
    "\n",
    "            fname = os.path.join(mean_output_folder, f\"mean_z_temperature_t_{t}.png\")\n",
    "            plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved plot as {fname}\")\n",
    "\n",
    "    print(\"All done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### High Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T20:31:25.434417Z",
     "iopub.status.busy": "2025-01-15T20:31:25.434201Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Dask graph. No data is read yet. Now calling .compute() with a ProgressBar...\n"
     ]
    }
   ],
   "source": [
    "# Suppose 'jhf_hr_zarr' is a zarr Group with\n",
    "#  jhf_hr_zarr['energy'] shape [105, 2048, 2048, 2048, 1]\n",
    "#  jhf_hr_zarr['temperature'] ...\n",
    "#  jhf_hr_zarr['pressure'] ...\n",
    "#  jhf_hr_zarr['velocity'] ...\n",
    "\n",
    "variables = [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "\n",
    "plot_slices_and_mean_z(\n",
    "    ds_zarr_group=jhf_hr_zarr,\n",
    "    variables=variables,\n",
    "    time_start=0,\n",
    "    time_stop=105,  # up to but not including 105 => indices 0..104\n",
    "    time_step=5,\n",
    "    z_step=128,\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-15T14:53:23.702012Z",
     "iopub.status.idle": "2025-01-15T14:53:23.702232Z",
     "shell.execute_reply": "2025-01-15T14:53:23.702126Z",
     "shell.execute_reply.started": "2025-01-15T14:53:23.702117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_mean_temp_across_z(data_arrays, timesteps=range(0, 106, 5), data_type=\"original\", spacing=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across X\n",
    "\n",
    "- [ ] TODO if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Compare Zarr to NetCDF correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "def compare_zarr_and_netcdf(\n",
    "    zarr_ds, \n",
    "    netcdf_path_pattern, \n",
    "    times=range(93, 105),\n",
    "    z_slice=64,  # how much of Z dimension to compare\n",
    "    y_slice=64,\n",
    "    x_slice=64\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare temperature data between a Zarr dataset and multiple NetCDF files\n",
    "    for all requested timesteps at once. Prints True/False per timestep.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zarr_ds : xarray.Dataset or dict-like of Dask arrays\n",
    "        Should have zarr_ds['temperature'] as a Dask-backed array of shape\n",
    "        [time, z, y, x, ...].\n",
    "    netcdf_path_pattern : str\n",
    "        File path pattern for NetCDF files, e.g. \"path/to/jhf.*.nc\". \n",
    "        We'll open them with xarray.open_mfdataset(...).\n",
    "    times : iterable\n",
    "        Timesteps to compare. E.g. range(93, 105).\n",
    "    z_slice, y_slice, x_slice : int\n",
    "        Number of grid cells in each dimension to compare\n",
    "        from [0:z_slice], etc.\n",
    "    \"\"\"\n",
    "\n",
    "    #---------------------\n",
    "    # 1) OPEN NETCDFs\n",
    "    #---------------------\n",
    "    # The idea is to let xarray + dask do all the heavy lifting in parallel.\n",
    "    # 'concat_dim=\"time\"' or 'combine=\"nested\"' depends on your file structure.\n",
    "    # Adjust as needed if the times are encoded differently.\n",
    "    ds_nc = xr.open_mfdataset(\n",
    "        netcdf_path_pattern, \n",
    "        # If each file is a single time, and you want them stacked on \"time\":\n",
    "        concat_dim=\"time\",\n",
    "        combine=\"nested\",\n",
    "        parallel=True,\n",
    "        # It's a good idea to chunk so we don't read the entire file at once\n",
    "        chunks={\n",
    "            \"nnz\": 64, \n",
    "            \"nny\": 64, \n",
    "            \"nnx\": 64  # or whatever chunk sizes make sense\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #---------------------\n",
    "    # 2) BUILD DASK ARRAYS\n",
    "    #---------------------\n",
    "    # We'll slice all requested times in one shot.\n",
    "    \n",
    "    # Zarr data: shape might be [time, Z, Y, X, 1] if scalar\n",
    "    zarr_temp = zarr_ds['temperature'].isel(\n",
    "        time=times,  # e.g. [93..105)\n",
    "        z=slice(0, z_slice),\n",
    "        y=slice(0, y_slice),\n",
    "        x=slice(0, x_slice),\n",
    "        component=0  # or .squeeze(axis=-1), if it’s always 1\n",
    "    )\n",
    "    \n",
    "    # NetCDF data: shape might be [time, nnz, nny, nnx]\n",
    "    nc_temp = ds_nc['t'].isel(\n",
    "        time=times,\n",
    "        nnz=slice(0, z_slice),\n",
    "        nny=slice(0, y_slice),\n",
    "        nnx=slice(0, x_slice)\n",
    "    )\n",
    "\n",
    "    # Both 'zarr_temp' and 'nc_temp' are still lazy Dask arrays.\n",
    "    # They should align to shape: [nTimes, Z, Y, X].\n",
    "\n",
    "    #---------------------\n",
    "    # 3) LAZY COMPARISON\n",
    "    #---------------------\n",
    "    # Instead of np.all(...) in a loop, do a single big comparison.\n",
    "    # eq => shape [nTimes, Z, Y, X], a bool Dask array\n",
    "    eq = (zarr_temp == nc_temp)\n",
    "\n",
    "    # If you want a per-timestep True/False, reduce over spatial dims only:\n",
    "    # eq_per_timestep => shape [nTimes]\n",
    "    eq_per_timestep = eq.all(axis=(1, 2, 3))\n",
    "\n",
    "    #---------------------\n",
    "    # 4) TRIGGER COMPUTE\n",
    "    #---------------------\n",
    "    # This is ONE pass that will pull all the data needed from both \n",
    "    # Zarr and NetCDF, using Dask’s parallel IO.\n",
    "    result = eq_per_timestep.compute()\n",
    "\n",
    "    #---------------------\n",
    "    # 5) REPORT RESULTS\n",
    "    #---------------------\n",
    "    # 'result' is a boolean numpy array, one entry per requested timestep\n",
    "    for idx, t in enumerate(times):\n",
    "        print(f\"t: {t}, match: {result[idx]}\")\n",
    "\n",
    "    # Optionally close the NetCDF dataset\n",
    "    ds_nc.close()\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# USAGE EXAMPLE\n",
    "#-------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import zarr\n",
    "    import xarray as xr\n",
    "    \n",
    "    # Suppose you already have your zarr dataset open as `jhf_hr_zarr`:\n",
    "    # jhf_hr_zarr = xarray.open_zarr(\"path/to/zarr_dir\") \n",
    "    # or zarr.open_group(...) and wrapped in an xarray Dataset\n",
    "    #\n",
    "    # netcdf_path_pattern might be:\n",
    "    # \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.*.nc\"\n",
    "\n",
    "    times_to_compare = range(93, 105)  # 12 timesteps\n",
    "    compare_zarr_and_netcdf(\n",
    "        zarr_ds=jhf_hr_zarr, \n",
    "        netcdf_path_pattern=\"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.*.nc\",\n",
    "        times=times_to_compare,\n",
    "        z_slice=64,\n",
    "        y_slice=64,\n",
    "        x_slice=64\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
