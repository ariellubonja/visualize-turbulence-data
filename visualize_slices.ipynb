{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used to sanity-check data: plotting raw and written files, calculating various statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:05:20.989602Z",
     "iopub.status.busy": "2025-01-15T19:05:20.989301Z",
     "iopub.status.idle": "2025-01-15T19:05:20.995491Z",
     "shell.execute_reply": "2025-01-15T19:05:20.994885Z",
     "shell.execute_reply.started": "2025-01-15T19:05:20.989559Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_hr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048high/stsabl2048high.zarr\"\n",
    "raw_jhf_hr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.000.nc\"\n",
    "raw_jhf_hr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.001.nc\"\n",
    "raw_jhf_hr_104_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.104.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:05:21.115232Z",
     "iopub.status.busy": "2025-01-15T19:05:21.115043Z",
     "iopub.status.idle": "2025-01-15T19:05:21.618131Z",
     "shell.execute_reply": "2025-01-15T19:05:21.617449Z",
     "shell.execute_reply.started": "2025-01-15T19:05:21.115220Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "jhf_hr_zarr = zarr.open(stored_jhf_hr_path)\n",
    "jhf_hr_netcdf_t0 = xr.open_dataset(raw_jhf_hr_0_path)\n",
    "jhf_hr_netcdf_t1 = xr.open_dataset(raw_jhf_hr_1_path)\n",
    "jhf_hr_netcdf_t104 = xr.open_dataset(raw_jhf_hr_104_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:05:21.619579Z",
     "iopub.status.busy": "2025-01-15T19:05:21.619238Z",
     "iopub.status.idle": "2025-01-15T19:05:21.652561Z",
     "shell.execute_reply": "2025-01-15T19:05:21.651950Z",
     "shell.execute_reply.started": "2025-01-15T19:05:21.619564Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_lr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048low/stsabl2048low.zarr\"\n",
    "raw_jhf_lr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.000.nc\"\n",
    "raw_jhf_lr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.001.nc\"\n",
    "raw_jhf_lr_19_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.019.nc\"\n",
    "\n",
    "\n",
    "jhf_lr_zarr = zarr.open(stored_jhf_lr_path)\n",
    "jhf_lr_netcdf_t0 = xr.open_dataset(raw_jhf_lr_0_path)\n",
    "jhf_lr_netcdf_t1 = xr.open_dataset(raw_jhf_lr_1_path)\n",
    "jhf_lr_netcdf_t19 = xr.open_dataset(raw_jhf_lr_19_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"cyan\">\n",
    "\n",
    "# Remember, data is saved in `nnz-nny-nnx`\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Quick-Verify Correctness of data\n",
    "\n",
    "1. Check if `data == 0`\n",
    "\n",
    "2. Pick one $64^3$ chunk and compare it to raw NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### `zarr.info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['velocity'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Indexing, Compare to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Checking whether field all zeros - True is bad!\")\n",
    "\n",
    "for t in range(105):\n",
    "    print(\"t=\", t, \" - \", np.all(jhf_hr_zarr['temperature'][t,:64,:64,:64,0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][1,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-01-15T14:50:41.857673Z",
     "shell.execute_reply": "2025-01-15T14:50:41.857091Z",
     "shell.execute_reply.started": "2025-01-15T14:44:20.357009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  97 True\n",
      "t:  98 True\n",
      "t:  99 True\n",
      "t:  100 True\n",
      "t:  101 True\n",
      "t:  102 True\n",
      "t:  103 True\n",
      "t:  104 True\n"
     ]
    }
   ],
   "source": [
    "for t in range(93, 105):\n",
    "    zarr_comparison_data = jhf_hr_zarr['temperature'][t,:64,:64,:64,0]\n",
    "\n",
    "    raw_t_path = f\"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.{t:03d}.nc\"\n",
    "    raw_xr = xr.open_dataset(raw_t_path)\n",
    "    raw_t = raw_xr['t'].isel(nnx=slice(0, 64), nny=slice(0, 64), nnz=slice(0, 64)).values\n",
    "    \n",
    "    print(\"t: \", t, np.all(zarr_comparison_data == raw_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,0,0,:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_hr_netcdf_t0['e'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Xarray complains about missing metadata. NOT Fixed by GPT o1\n",
    "\n",
    "`written_ds_xr = xr.open_dataset(stored_jhf_path, engine='zarr', consolidated=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][0, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['energy'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_lr_netcdf_t0['t'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Efficient Zarr full data Slices\n",
    "\n",
    "This can take a few minutes\n",
    "\n",
    " Sciserver doesn't allow localhost connections, so can't use Dask Cluster console Sciserver doesn't allow localhost connections, so can't use Dask Cluster console\n",
    " \n",
    "<font color=\"green\"> Lazy loading speeds up reading times 10x+</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T17:36:10.638762Z",
     "iopub.status.busy": "2025-01-15T17:36:10.638516Z",
     "iopub.status.idle": "2025-01-15T17:36:10.651136Z",
     "shell.execute_reply": "2025-01-15T17:36:10.650513Z",
     "shell.execute_reply.started": "2025-01-15T17:36:10.638744Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "def process_zarr(stored_jhf_path, dataset):\n",
    "    if dataset not in ['hr', 'lr']:\n",
    "        raise ValueError(\"Dataset must be 'hr' or 'lr'.\")\n",
    "\n",
    "    # Open the Zarr group\n",
    "    store = zarr.open_group(stored_jhf_path, mode='r')\n",
    "\n",
    "    # Create Dask arrays\n",
    "    data_arrays = {}\n",
    "    variables = list(store.array_keys())\n",
    "    for var_name in variables:\n",
    "        zarr_array = store[var_name]\n",
    "        dask_array = da.from_zarr(zarr_array)\n",
    "        # Squeeze scalar variables\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)\n",
    "        data_arrays[var_name] = dask_array\n",
    "\n",
    "    # Function to collect data slices\n",
    "    def collect_data_slices(data_arrays, variables, timesteps):\n",
    "        data_slices = []\n",
    "        titles = []\n",
    "        \n",
    "        for variable in variables:\n",
    "            for timestep in timesteps:\n",
    "                dask_array = data_arrays[variable]\n",
    "                \n",
    "                # Get slices along each dimension (assuming shape = [time, Z, Y, X] or similar)\n",
    "                x_slice = dask_array[timestep, :, :, 0]\n",
    "                y_slice = dask_array[timestep, :, 0, :]\n",
    "                z_slice = dask_array[timestep, 0, :, :]\n",
    "                \n",
    "                # For vector variables, handle components\n",
    "                if variable == 'velocity':\n",
    "                    for component in range(3):\n",
    "                        x_comp_slice = x_slice[..., component]\n",
    "                        y_comp_slice = y_slice[..., component]\n",
    "                        z_comp_slice = z_slice[..., component]\n",
    "                        \n",
    "                        data_slices.extend([x_comp_slice, y_comp_slice, z_comp_slice])\n",
    "                        titles.extend([\n",
    "                            f\"{variable} (component {component}) nnx=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nny=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nnz=0 Timestep={timestep}\"\n",
    "                        ])\n",
    "                else:\n",
    "                    data_slices.extend([x_slice, y_slice, z_slice])\n",
    "                    titles.extend([\n",
    "                        f\"{variable} nnx=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nny=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nnz=0 Timestep={timestep}\"\n",
    "                    ])\n",
    "        return data_slices, titles\n",
    "\n",
    "    # Choose timesteps: here every 5th until the end\n",
    "    timesteps = range(0, data_arrays['energy'].shape[0], 5)  \n",
    "\n",
    "    # Collect data slices\n",
    "    data_slices, titles = collect_data_slices(data_arrays, ['energy', 'temperature', 'pressure', 'velocity'], timesteps)\n",
    "\n",
    "    # Compute all data slices at once (lazy -> single compute call)\n",
    "    with ProgressBar():\n",
    "        computed_slices = compute(*data_slices)\n",
    "\n",
    "    # Plot (and now save) all images\n",
    "    # Create a master folder for all slices\n",
    "    master_folder = os.path.join(\"zarr_slices\", dataset)\n",
    "    os.makedirs(master_folder, exist_ok=True)\n",
    "\n",
    "    idx = 0\n",
    "    for variable in ['energy', 'temperature', 'pressure', 'velocity']:\n",
    "        # Make a folder per variable\n",
    "        var_folder = os.path.join(master_folder, variable)\n",
    "        os.makedirs(var_folder, exist_ok=True)\n",
    "        \n",
    "        # We'll have 3 slices per timestep if scalar,\n",
    "        # or 9 slices per timestep if velocity (3 components * 3 slices).\n",
    "        # So we figure out how many slices belong to each variable:\n",
    "        if variable == 'velocity':\n",
    "            slices_per_timestep = 9\n",
    "        else:\n",
    "            slices_per_timestep = 3\n",
    "        \n",
    "        for timestep in timesteps:\n",
    "            # For velocity, we handle 9 images; for others, 3.\n",
    "            subset = computed_slices[idx : idx + slices_per_timestep]\n",
    "            subset_titles = titles[idx : idx + slices_per_timestep]\n",
    "            \n",
    "            for data_slice, title in zip(subset, subset_titles):\n",
    "                plt.figure()\n",
    "                plt.imshow(data_slice)\n",
    "                plt.title(title)\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.colorbar()\n",
    "                \n",
    "                # Create a filename for saving\n",
    "                safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                filename = os.path.join(var_folder, f\"Timestep_{timestep}_{safe_title}.png\")\n",
    "                plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            \n",
    "            idx += slices_per_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T17:36:10.779513Z",
     "iopub.status.busy": "2025-01-15T17:36:10.779371Z",
     "iopub.status.idle": "2025-01-15T17:37:53.271401Z",
     "shell.execute_reply": "2025-01-15T17:37:53.270752Z",
     "shell.execute_reply.started": "2025-01-15T17:36:10.779500Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 52.64 s\n"
     ]
    }
   ],
   "source": [
    "process_zarr(stored_jhf_lr_path, \"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Statistics - Mean Temp. across Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### High Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:15:50.454112Z",
     "iopub.status.busy": "2025-01-15T19:15:50.453872Z",
     "iopub.status.idle": "2025-01-15T19:15:50.457551Z",
     "shell.execute_reply": "2025-01-15T19:15:50.456842Z",
     "shell.execute_reply.started": "2025-01-15T19:15:50.454096Z"
    }
   },
   "outputs": [],
   "source": [
    "stored_jhf_path = stored_jhf_hr_path\n",
    "\n",
    "process_dataset = \"high_rate\"\n",
    "\n",
    "ds = jhf_hr_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:15:50.922902Z",
     "iopub.status.busy": "2025-01-15T19:15:50.922634Z",
     "iopub.status.idle": "2025-01-15T19:28:22.959101Z",
     "shell.execute_reply": "2025-01-15T19:28:22.958249Z",
     "shell.execute_reply.started": "2025-01-15T19:15:50.922885Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 487.52 s\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 163\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved plot as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Now call it:\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m \u001b[43mplot_mean_temp_across_z\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m106\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzarr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspacing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [14], line 119\u001b[0m, in \u001b[0;36mplot_mean_temp_across_z\u001b[0;34m(ds, timesteps, data_type, spacing)\u001b[0m\n\u001b[1;32m    117\u001b[0m lazy_means_per_t \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m timesteps:\n\u001b[0;32m--> 119\u001b[0m     temp_slice \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    120\u001b[0m     temp_sliced \u001b[38;5;241m=\u001b[39m temp_slice[\u001b[38;5;28mlist\u001b[39m(z_indices), :, :]\n\u001b[1;32m    121\u001b[0m     z_means \u001b[38;5;241m=\u001b[39m temp_sliced\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/dask/array/core.py:1962\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m   1954\u001b[0m     index \u001b[38;5;241m=\u001b[39m (index,)\n\u001b[1;32m   1956\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslicing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m   1957\u001b[0m     normalize_index,\n\u001b[1;32m   1958\u001b[0m     slice_with_bool_dask_array,\n\u001b[1;32m   1959\u001b[0m     slice_with_int_dask_array,\n\u001b[1;32m   1960\u001b[0m )\n\u001b[0;32m-> 1962\u001b[0m index2 \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m dependencies \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname}\n\u001b[1;32m   1964\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m index2:\n",
      "File \u001b[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/dask/array/slicing.py:904\u001b[0m, in \u001b[0;36mnormalize_index\u001b[0;34m(idx, shape)\u001b[0m\n\u001b[1;32m    902\u001b[0m idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m),) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m-\u001b[39m n_sliced_dims)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape):\n\u001b[0;32m--> 904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indices for array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    906\u001b[0m none_shape \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    907\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: Too many indices for array"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "# ==============\n",
    "# 1) OPEN ZARR\n",
    "# ==============\n",
    "store = zarr.open_group(stored_jhf_path, mode='r')\n",
    "\n",
    "data_arrays = {}\n",
    "for var_name in store.array_keys():\n",
    "    zarr_array = store[var_name]\n",
    "    dask_array = da.from_zarr(zarr_array)\n",
    "    # Squeeze scalar variables\n",
    "    if dask_array.shape[-1] == 1:\n",
    "        dask_array = dask_array.squeeze(axis=-1)\n",
    "    data_arrays[var_name] = dask_array\n",
    "\n",
    "# ==============\n",
    "# 2) SLICE PLOTS\n",
    "# ==============\n",
    "def collect_data_slices(data_arrays, variables, timesteps):\n",
    "    data_slices = []\n",
    "    titles = []\n",
    "    for variable in variables:\n",
    "        for timestep in timesteps:\n",
    "            dask_array = data_arrays[variable]\n",
    "            # Slices for [time, Z, Y, X], we pick X=0, Y=0, Z=0\n",
    "            x_slice = dask_array[timestep, :, :, 0]\n",
    "            y_slice = dask_array[timestep, :, 0, :]\n",
    "            z_slice = dask_array[timestep, 0, :, :]\n",
    "\n",
    "            if variable == 'velocity':\n",
    "                for component in range(3):\n",
    "                    data_slices.extend([\n",
    "                        x_slice[..., component],\n",
    "                        y_slice[..., component],\n",
    "                        z_slice[..., component]\n",
    "                    ])\n",
    "                    titles.extend([\n",
    "                        f\"{variable} (component {component}) nnx=0 Timestep={timestep}\",\n",
    "                        f\"{variable} (component {component}) nny=0 Timestep={timestep}\",\n",
    "                        f\"{variable} (component {component}) nnz=0 Timestep={timestep}\"\n",
    "                    ])\n",
    "            else:\n",
    "                data_slices.extend([x_slice, y_slice, z_slice])\n",
    "                titles.extend([\n",
    "                    f\"{variable} nnx=0 Timestep={timestep}\",\n",
    "                    f\"{variable} nny=0 Timestep={timestep}\",\n",
    "                    f\"{variable} nnz=0 Timestep={timestep}\"\n",
    "                ])\n",
    "    return data_slices, titles\n",
    "\n",
    "variables = ['energy', 'temperature', 'pressure', 'velocity']\n",
    "timesteps = range(0, data_arrays['energy'].shape[0], 5)\n",
    "\n",
    "data_slices, titles = collect_data_slices(data_arrays, variables, timesteps)\n",
    "\n",
    "# Single compute for all slice data\n",
    "with ProgressBar():\n",
    "    computed_slices = compute(*data_slices)\n",
    "\n",
    "# Save slice images: \"zarr_slices/variable/*.png\"\n",
    "master_folder = \"zarr_slices\"\n",
    "os.makedirs(master_folder, exist_ok=True)\n",
    "\n",
    "idx = 0\n",
    "for var in variables:\n",
    "    var_folder = os.path.join(master_folder, var)\n",
    "    os.makedirs(var_folder, exist_ok=True)\n",
    "    \n",
    "    # For velocity, 9 per timestep (3 comps × 3 slices),\n",
    "    # for scalars, 3 per timestep.\n",
    "    slices_per_timestep = 9 if var == \"velocity\" else 3\n",
    "    \n",
    "    for t in timesteps:\n",
    "        subset = computed_slices[idx : idx + slices_per_timestep]\n",
    "        subset_titles = titles[idx : idx + slices_per_timestep]\n",
    "        \n",
    "        for data_slice, title in zip(subset, subset_titles):\n",
    "            plt.figure()\n",
    "            plt.imshow(data_slice)\n",
    "            plt.title(title)\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.colorbar()\n",
    "\n",
    "            fname = title.replace(\" \", \"_\").replace(\"=\", \"_\") + \".png\"\n",
    "            plt.savefig(os.path.join(var_folder, fname), dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        idx += slices_per_timestep\n",
    "\n",
    "# ==============\n",
    "# 3) MEAN TEMP\n",
    "# ==============\n",
    "def plot_mean_temp_across_z(\n",
    "    ds, \n",
    "    timesteps,\n",
    "    data_type: Literal[\"zarr\", \"original\"],\n",
    "    spacing: int = 128\n",
    "):\n",
    "    if data_type not in (\"zarr\", \"original\"):\n",
    "        raise ValueError(\"data_type must be either 'zarr' or 'original'\")\n",
    "\n",
    "    output_folder = \"mean_temperature_plots\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    z_indices = range(0, ds['temperature'].shape[1], spacing)\n",
    "\n",
    "    if data_type == \"zarr\":\n",
    "        # Build lazy ops for all timesteps\n",
    "        lazy_means_per_t = []\n",
    "        for t in timesteps:\n",
    "            temp_slice = ds['temperature'][t, :, :, :, 0]\n",
    "            temp_sliced = temp_slice[list(z_indices), :, :]\n",
    "            z_means = temp_sliced.mean(axis=(1,2))\n",
    "            lazy_means_per_t.append(z_means)\n",
    "\n",
    "        # One big array: shape [num_timesteps, len(z_indices)]\n",
    "        stacked = da.stack(lazy_means_per_t, axis=0)\n",
    "        # Single compute\n",
    "        computed = stacked.compute()\n",
    "\n",
    "        # Plot each row\n",
    "        for i, t in enumerate(timesteps):\n",
    "            xy_means = computed[i]\n",
    "            plt.figure()\n",
    "            plt.plot(list(z_indices), xy_means, marker='o')\n",
    "            plt.title(f\"Mean Temperature across Z (t={t}, data_type={data_type})\")\n",
    "            plt.xlabel(\"Slice (Z)\")\n",
    "            plt.ylabel(\"Avg Temperature\")\n",
    "            \n",
    "            fname = os.path.join(output_folder, f\"mean_z_temperature_{data_type}_t_{t}.png\")\n",
    "            plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved plot as {fname}\")\n",
    "\n",
    "    else:  # data_type == 'original'\n",
    "        # Possibly still a loop, but it's real NumPy so no Dask\n",
    "        for t in timesteps:\n",
    "            xy_means = []\n",
    "            for z in z_indices:\n",
    "                xy_means.append(ds['temperature'][t, z, :, :, 0].mean())\n",
    "            \n",
    "            # Plot\n",
    "            plt.figure()\n",
    "            plt.plot(list(z_indices), xy_means, marker='o')\n",
    "            plt.title(f\"Mean Temperature across Z (t={t}, data_type={data_type})\")\n",
    "            plt.xlabel(\"Slice (Z)\")\n",
    "            plt.ylabel(\"Avg Temperature\")\n",
    "            \n",
    "            fname = os.path.join(output_folder, f\"mean_z_temperature_{data_type}_t_{t}.png\")\n",
    "            plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved plot as {fname}\")\n",
    "\n",
    "\n",
    "plot_mean_temp_across_z(data_arrays, timesteps=range(0, 106, 5), data_type=\"zarr\", spacing=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T19:38:09.637882Z",
     "iopub.status.busy": "2025-01-15T19:38:09.637639Z",
     "iopub.status.idle": "2025-01-15T19:38:09.663407Z",
     "shell.execute_reply": "2025-01-15T19:38:09.662894Z",
     "shell.execute_reply.started": "2025-01-15T19:38:09.637867Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/temperature</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">float32</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(105, 2048, 2048, 2048, 1)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(1, 64, 64, 64, 1)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">False</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">None</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">3607772528640 (3.3T)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">329</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">10965873947.2</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">105/3440640</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name               : /temperature\n",
       "Type               : zarr.core.Array\n",
       "Data type          : float32\n",
       "Shape              : (105, 2048, 2048, 2048, 1)\n",
       "Chunk shape        : (1, 64, 64, 64, 1)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Compressor         : None\n",
       "Store type         : zarr.storage.DirectoryStore\n",
       "No. bytes          : 3607772528640 (3.3T)\n",
       "No. bytes stored   : 329\n",
       "Storage ratio      : 10965873947.2\n",
       "Chunks initialized : 105/3440640"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['temperature'].info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Across Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppose you've already got a dictionary-like `ds` with:\n",
    "# ds[\"energy\"], ds[\"temperature\"], ds[\"pressure\"], ds[\"velocity\"] \n",
    "# as Dask arrays (from .from_zarr), each shape ~ [time, z, y, x, (maybe 3 for velocity)]\n",
    "\n",
    "variables = [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "timesteps = range(0, ds[\"energy\"].shape[0], 5)  # or [0, 5, 10, ..., 105]\n",
    "\n",
    "plot_slices_and_mean(\n",
    "    ds,\n",
    "    variables,\n",
    "    timesteps,\n",
    "    data_type=\"zarr\",    # so we do the lazy means\n",
    "    spacing=128,         # how often to sample Z dimension for the mean\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-15T14:53:23.702012Z",
     "iopub.status.idle": "2025-01-15T14:53:23.702232Z",
     "shell.execute_reply": "2025-01-15T14:53:23.702126Z",
     "shell.execute_reply.started": "2025-01-15T14:53:23.702117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_mean_temp_across_z(data_arrays, timesteps=range(0, 106, 5), data_type=\"original\", spacing=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across X\n",
    "\n",
    "- [ ] TODO if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Zarr to NetCDF correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "def compare_zarr_and_netcdf(\n",
    "    zarr_ds, \n",
    "    netcdf_path_pattern, \n",
    "    times=range(93, 105),\n",
    "    z_slice=64,  # how much of Z dimension to compare\n",
    "    y_slice=64,\n",
    "    x_slice=64\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare temperature data between a Zarr dataset and multiple NetCDF files\n",
    "    for all requested timesteps at once. Prints True/False per timestep.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zarr_ds : xarray.Dataset or dict-like of Dask arrays\n",
    "        Should have zarr_ds['temperature'] as a Dask-backed array of shape\n",
    "        [time, z, y, x, ...].\n",
    "    netcdf_path_pattern : str\n",
    "        File path pattern for NetCDF files, e.g. \"path/to/jhf.*.nc\". \n",
    "        We'll open them with xarray.open_mfdataset(...).\n",
    "    times : iterable\n",
    "        Timesteps to compare. E.g. range(93, 105).\n",
    "    z_slice, y_slice, x_slice : int\n",
    "        Number of grid cells in each dimension to compare\n",
    "        from [0:z_slice], etc.\n",
    "    \"\"\"\n",
    "\n",
    "    #---------------------\n",
    "    # 1) OPEN NETCDFs\n",
    "    #---------------------\n",
    "    # The idea is to let xarray + dask do all the heavy lifting in parallel.\n",
    "    # 'concat_dim=\"time\"' or 'combine=\"nested\"' depends on your file structure.\n",
    "    # Adjust as needed if the times are encoded differently.\n",
    "    ds_nc = xr.open_mfdataset(\n",
    "        netcdf_path_pattern, \n",
    "        # If each file is a single time, and you want them stacked on \"time\":\n",
    "        concat_dim=\"time\",\n",
    "        combine=\"nested\",\n",
    "        parallel=True,\n",
    "        # It's a good idea to chunk so we don't read the entire file at once\n",
    "        chunks={\n",
    "            \"nnz\": 64, \n",
    "            \"nny\": 64, \n",
    "            \"nnx\": 64  # or whatever chunk sizes make sense\n",
    "        }\n",
    "    )\n",
    "\n",
    "    #---------------------\n",
    "    # 2) BUILD DASK ARRAYS\n",
    "    #---------------------\n",
    "    # We'll slice all requested times in one shot.\n",
    "    \n",
    "    # Zarr data: shape might be [time, Z, Y, X, 1] if scalar\n",
    "    zarr_temp = zarr_ds['temperature'].isel(\n",
    "        time=times,  # e.g. [93..105)\n",
    "        z=slice(0, z_slice),\n",
    "        y=slice(0, y_slice),\n",
    "        x=slice(0, x_slice),\n",
    "        component=0  # or .squeeze(axis=-1), if it’s always 1\n",
    "    )\n",
    "    \n",
    "    # NetCDF data: shape might be [time, nnz, nny, nnx]\n",
    "    nc_temp = ds_nc['t'].isel(\n",
    "        time=times,\n",
    "        nnz=slice(0, z_slice),\n",
    "        nny=slice(0, y_slice),\n",
    "        nnx=slice(0, x_slice)\n",
    "    )\n",
    "\n",
    "    # Both 'zarr_temp' and 'nc_temp' are still lazy Dask arrays.\n",
    "    # They should align to shape: [nTimes, Z, Y, X].\n",
    "\n",
    "    #---------------------\n",
    "    # 3) LAZY COMPARISON\n",
    "    #---------------------\n",
    "    # Instead of np.all(...) in a loop, do a single big comparison.\n",
    "    # eq => shape [nTimes, Z, Y, X], a bool Dask array\n",
    "    eq = (zarr_temp == nc_temp)\n",
    "\n",
    "    # If you want a per-timestep True/False, reduce over spatial dims only:\n",
    "    # eq_per_timestep => shape [nTimes]\n",
    "    eq_per_timestep = eq.all(axis=(1, 2, 3))\n",
    "\n",
    "    #---------------------\n",
    "    # 4) TRIGGER COMPUTE\n",
    "    #---------------------\n",
    "    # This is ONE pass that will pull all the data needed from both \n",
    "    # Zarr and NetCDF, using Dask’s parallel IO.\n",
    "    result = eq_per_timestep.compute()\n",
    "\n",
    "    #---------------------\n",
    "    # 5) REPORT RESULTS\n",
    "    #---------------------\n",
    "    # 'result' is a boolean numpy array, one entry per requested timestep\n",
    "    for idx, t in enumerate(times):\n",
    "        print(f\"t: {t}, match: {result[idx]}\")\n",
    "\n",
    "    # Optionally close the NetCDF dataset\n",
    "    ds_nc.close()\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# USAGE EXAMPLE\n",
    "#-------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import zarr\n",
    "    import xarray as xr\n",
    "    \n",
    "    # Suppose you already have your zarr dataset open as `jhf_hr_zarr`:\n",
    "    # jhf_hr_zarr = xarray.open_zarr(\"path/to/zarr_dir\") \n",
    "    # or zarr.open_group(...) and wrapped in an xarray Dataset\n",
    "    #\n",
    "    # netcdf_path_pattern might be:\n",
    "    # \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.*.nc\"\n",
    "\n",
    "    times_to_compare = range(93, 105)  # 12 timesteps\n",
    "    compare_zarr_and_netcdf(\n",
    "        zarr_ds=jhf_hr_zarr, \n",
    "        netcdf_path_pattern=\"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.*.nc\",\n",
    "        times=times_to_compare,\n",
    "        z_slice=64,\n",
    "        y_slice=64,\n",
    "        x_slice=64\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
