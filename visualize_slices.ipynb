{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used to sanity-check data: plotting raw and written files, calculating various statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:03:24.560756Z",
     "iopub.status.busy": "2025-01-15T18:03:24.560117Z",
     "iopub.status.idle": "2025-01-15T18:03:24.566499Z",
     "shell.execute_reply": "2025-01-15T18:03:24.565843Z",
     "shell.execute_reply.started": "2025-01-15T18:03:24.560712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_hr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048high/stsabl2048high.zarr\"\n",
    "raw_jhf_hr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.000.nc\"\n",
    "raw_jhf_hr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.001.nc\"\n",
    "raw_jhf_hr_104_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.104.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:03:24.567620Z",
     "iopub.status.busy": "2025-01-15T18:03:24.567381Z",
     "iopub.status.idle": "2025-01-15T18:03:25.064006Z",
     "shell.execute_reply": "2025-01-15T18:03:25.063302Z",
     "shell.execute_reply.started": "2025-01-15T18:03:24.567604Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zarr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "jhf_hr_zarr = zarr.open(stored_jhf_hr_path)\n",
    "jhf_hr_netcdf_t0 = xr.open_dataset(raw_jhf_hr_0_path)\n",
    "jhf_hr_netcdf_t1 = xr.open_dataset(raw_jhf_hr_1_path)\n",
    "jhf_hr_netcdf_t104 = xr.open_dataset(raw_jhf_hr_104_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:03:25.065483Z",
     "iopub.status.busy": "2025-01-15T18:03:25.065143Z",
     "iopub.status.idle": "2025-01-15T18:03:25.097201Z",
     "shell.execute_reply": "2025-01-15T18:03:25.096587Z",
     "shell.execute_reply.started": "2025-01-15T18:03:25.065468Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_lr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048low/stsabl2048low.zarr\"\n",
    "raw_jhf_lr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.000.nc\"\n",
    "raw_jhf_lr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.001.nc\"\n",
    "raw_jhf_lr_19_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.019.nc\"\n",
    "\n",
    "\n",
    "jhf_lr_zarr = zarr.open(stored_jhf_lr_path)\n",
    "jhf_lr_netcdf_t0 = xr.open_dataset(raw_jhf_lr_0_path)\n",
    "jhf_lr_netcdf_t1 = xr.open_dataset(raw_jhf_lr_1_path)\n",
    "jhf_lr_netcdf_t19 = xr.open_dataset(raw_jhf_lr_19_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='cyan'>\n",
    "\n",
    "## Remember, index is nnz-nny-nnx. first dim is Z\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"cyan\">\n",
    "\n",
    "# Remember, data is saved in `nnz-nny-nnx`\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Quick-Verify Correctness of data\n",
    "\n",
    "1. Check if `data == 0`\n",
    "\n",
    "2. Pick one $64^3$ chunk and compare it to raw NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### `zarr.info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['velocity'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Indexing, Compare to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Checking whether field all zeros - True is bad!\")\n",
    "\n",
    "for t in range(105):\n",
    "    print(\"t=\", t, \" - \", np.all(jhf_hr_zarr['temperature'][t,:64,:64,:64,0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][1,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-01-15T14:50:41.857673Z",
     "shell.execute_reply": "2025-01-15T14:50:41.857091Z",
     "shell.execute_reply.started": "2025-01-15T14:44:20.357009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  97 True\n",
      "t:  98 True\n",
      "t:  99 True\n",
      "t:  100 True\n",
      "t:  101 True\n",
      "t:  102 True\n",
      "t:  103 True\n",
      "t:  104 True\n"
     ]
    }
   ],
   "source": [
    "for t in range(93, 105):\n",
    "    zarr_comparison_data = jhf_hr_zarr['temperature'][t,:64,:64,:64,0]\n",
    "\n",
    "    raw_t_path = f\"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.{t:03d}.nc\"\n",
    "    raw_xr = xr.open_dataset(raw_t_path)\n",
    "    raw_t = raw_xr['t'].isel(nnx=slice(0, 64), nny=slice(0, 64), nnz=slice(0, 64)).values\n",
    "    \n",
    "    print(\"t: \", t, np.all(zarr_comparison_data == raw_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,0,0,:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_hr_netcdf_t0['e'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Xarray complains about missing metadata. NOT Fixed by GPT o1\n",
    "\n",
    "`written_ds_xr = xr.open_dataset(stored_jhf_path, engine='zarr', consolidated=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][0, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['energy'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_lr_netcdf_t0['t'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Efficient Zarr full data Slices\n",
    "\n",
    "This can take a few minutes\n",
    "\n",
    " Sciserver doesn't allow localhost connections, so can't use Dask Cluster console Sciserver doesn't allow localhost connections, so can't use Dask Cluster console\n",
    " \n",
    "<font color=\"green\"> Lazy loading speeds up reading times 10x+</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T17:36:10.638762Z",
     "iopub.status.busy": "2025-01-15T17:36:10.638516Z",
     "iopub.status.idle": "2025-01-15T17:36:10.651136Z",
     "shell.execute_reply": "2025-01-15T17:36:10.650513Z",
     "shell.execute_reply.started": "2025-01-15T17:36:10.638744Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "def process_zarr(stored_jhf_path, dataset):\n",
    "    if dataset not in ['hr', 'lr']:\n",
    "        raise ValueError(\"Dataset must be 'hr' or 'lr'.\")\n",
    "\n",
    "    # Open the Zarr group\n",
    "    store = zarr.open_group(stored_jhf_path, mode='r')\n",
    "\n",
    "    # Create Dask arrays\n",
    "    data_arrays = {}\n",
    "    variables = list(store.array_keys())\n",
    "    for var_name in variables:\n",
    "        zarr_array = store[var_name]\n",
    "        dask_array = da.from_zarr(zarr_array)\n",
    "        # Squeeze scalar variables\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)\n",
    "        data_arrays[var_name] = dask_array\n",
    "\n",
    "    # Function to collect data slices\n",
    "    def collect_data_slices(data_arrays, variables, timesteps):\n",
    "        data_slices = []\n",
    "        titles = []\n",
    "        \n",
    "        for variable in variables:\n",
    "            for timestep in timesteps:\n",
    "                dask_array = data_arrays[variable]\n",
    "                \n",
    "                # Get slices along each dimension (assuming shape = [time, Z, Y, X] or similar)\n",
    "                x_slice = dask_array[timestep, :, :, 0]\n",
    "                y_slice = dask_array[timestep, :, 0, :]\n",
    "                z_slice = dask_array[timestep, 0, :, :]\n",
    "                \n",
    "                # For vector variables, handle components\n",
    "                if variable == 'velocity':\n",
    "                    for component in range(3):\n",
    "                        x_comp_slice = x_slice[..., component]\n",
    "                        y_comp_slice = y_slice[..., component]\n",
    "                        z_comp_slice = z_slice[..., component]\n",
    "                        \n",
    "                        data_slices.extend([x_comp_slice, y_comp_slice, z_comp_slice])\n",
    "                        titles.extend([\n",
    "                            f\"{variable} (component {component}) nnx=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nny=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nnz=0 Timestep={timestep}\"\n",
    "                        ])\n",
    "                else:\n",
    "                    data_slices.extend([x_slice, y_slice, z_slice])\n",
    "                    titles.extend([\n",
    "                        f\"{variable} nnx=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nny=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nnz=0 Timestep={timestep}\"\n",
    "                    ])\n",
    "        return data_slices, titles\n",
    "\n",
    "    # Choose timesteps: here every 5th until the end\n",
    "    timesteps = range(0, data_arrays['energy'].shape[0], 5)  \n",
    "\n",
    "    # Collect data slices\n",
    "    data_slices, titles = collect_data_slices(data_arrays, ['energy', 'temperature', 'pressure', 'velocity'], timesteps)\n",
    "\n",
    "    # Compute all data slices at once (lazy -> single compute call)\n",
    "    with ProgressBar():\n",
    "        computed_slices = compute(*data_slices)\n",
    "\n",
    "    # Plot (and now save) all images\n",
    "    # Create a master folder for all slices\n",
    "    master_folder = os.path.join(\"zarr_slices\", dataset)\n",
    "    os.makedirs(master_folder, exist_ok=True)\n",
    "\n",
    "    idx = 0\n",
    "    for variable in ['energy', 'temperature', 'pressure', 'velocity']:\n",
    "        # Make a folder per variable\n",
    "        var_folder = os.path.join(master_folder, variable)\n",
    "        os.makedirs(var_folder, exist_ok=True)\n",
    "        \n",
    "        # We'll have 3 slices per timestep if scalar,\n",
    "        # or 9 slices per timestep if velocity (3 components * 3 slices).\n",
    "        # So we figure out how many slices belong to each variable:\n",
    "        if variable == 'velocity':\n",
    "            slices_per_timestep = 9\n",
    "        else:\n",
    "            slices_per_timestep = 3\n",
    "        \n",
    "        for timestep in timesteps:\n",
    "            # For velocity, we handle 9 images; for others, 3.\n",
    "            subset = computed_slices[idx : idx + slices_per_timestep]\n",
    "            subset_titles = titles[idx : idx + slices_per_timestep]\n",
    "            \n",
    "            for data_slice, title in zip(subset, subset_titles):\n",
    "                plt.figure()\n",
    "                plt.imshow(data_slice)\n",
    "                plt.title(title)\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.colorbar()\n",
    "                \n",
    "                # Create a filename for saving\n",
    "                safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                filename = os.path.join(var_folder, f\"Timestep_{timestep}_{safe_title}.png\")\n",
    "                plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            \n",
    "            idx += slices_per_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T17:36:10.779513Z",
     "iopub.status.busy": "2025-01-15T17:36:10.779371Z",
     "iopub.status.idle": "2025-01-15T17:37:53.271401Z",
     "shell.execute_reply": "2025-01-15T17:37:53.270752Z",
     "shell.execute_reply.started": "2025-01-15T17:36:10.779500Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 52.64 s\n"
     ]
    }
   ],
   "source": [
    "process_zarr(stored_jhf_lr_path, \"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Statistics - Mean Temp. across Axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:24:20.773949Z",
     "iopub.status.busy": "2025-01-15T18:24:20.773786Z",
     "iopub.status.idle": "2025-01-15T18:24:20.792392Z",
     "shell.execute_reply": "2025-01-15T18:24:20.791643Z",
     "shell.execute_reply.started": "2025-01-15T18:24:20.773936Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.array as da\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "from typing import Literal\n",
    "\n",
    "def plot_slices_and_mean(\n",
    "    ds, \n",
    "    variables, \n",
    "    timesteps, \n",
    "    data_type: Literal[\"zarr\", \"original\"] = \"zarr\",\n",
    "    spacing: int = 128,\n",
    "    master_slice_folder: str = \"zarr_slices\",\n",
    "    mean_output_folder: str = \"mean_temperature_plots\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Combines:\n",
    "      A) Slice-based plotting (X=0, Y=0, Z=0) for multiple variables\n",
    "      B) Mean-temperature plotting across Z\n",
    "    by building a single large Dask graph and doing one .compute()\n",
    "    to keep everything lazy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : dict-like or xarray-like \n",
    "        Should have ds[var] as a Dask (or NumPy) array with shape:\n",
    "        - For scalars (e.g. \"energy\"): [time, z, y, x]\n",
    "        - For vector variables (e.g. \"velocity\"): [time, z, y, x, 3]\n",
    "    variables : list of str\n",
    "        E.g. [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "    timesteps : iterable\n",
    "        E.g. range(0, ds[\"energy\"].shape[0], 5)\n",
    "    data_type : Literal[\"zarr\", \"original\"]\n",
    "        If \"zarr\", we assume ds[var] is Dask-backed. If \"original\", we assume\n",
    "        real NumPy arrays (less lazy).\n",
    "    spacing : int\n",
    "        Step size for Z in the mean-temperature calculation\n",
    "    master_slice_folder : str\n",
    "        Where to save slice plots (will have subfolders for each variable).\n",
    "    mean_output_folder : str\n",
    "        Where to save the mean-temperature plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1) PREPARE FOLDERS\n",
    "    # ------------------------------------------------------------------\n",
    "    os.makedirs(master_slice_folder, exist_ok=True)\n",
    "    os.makedirs(mean_output_folder, exist_ok=True)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2) COLLECT SLICE ARRAYS (X=0, Y=0, Z=0)\n",
    "    # ------------------------------------------------------------------\n",
    "    # We'll store them in lists so we can do a single compute\n",
    "    slice_arrays = []\n",
    "    slice_titles = []\n",
    "    # We'll need to remember how many slice-arrays belong to each variable+timestep\n",
    "    slice_counts_per_variable_timestep = {}\n",
    "\n",
    "    for var in variables:\n",
    "        # Decide how many slices per timestep\n",
    "        # - For scalar variables: 3 (X=0, Y=0, Z=0)\n",
    "        # - For velocity variable: 3*3=9 (3 components Ã— 3 slices)\n",
    "        if var == \"velocity\":\n",
    "            slices_per_ts = 9\n",
    "        else:\n",
    "            slices_per_ts = 3\n",
    "\n",
    "        slice_counts_per_variable_timestep[var] = slices_per_ts\n",
    "\n",
    "        for t in timesteps:\n",
    "            arr = ds[var]\n",
    "\n",
    "            # For scalars: arr.shape ~ [time, z, y, x]\n",
    "            # For velocity: arr.shape ~ [time, z, y, x, 3]\n",
    "\n",
    "            # Grab slices\n",
    "            #   x_slice = arr[t, :, :, 0]\n",
    "            #   y_slice = arr[t, :, 0, :]\n",
    "            #   z_slice = arr[t, 0, :, :]\n",
    "            # If velocity, there is an extra last dim for components\n",
    "            if var == \"velocity\":\n",
    "                x_slice = arr[t, :, :, 0, :]  # shape [z, y, 3]\n",
    "                y_slice = arr[t, :, 0, :, :]  # shape [z, x, 3]\n",
    "                z_slice = arr[t, 0, :, :, :]  # shape [y, x, 3]\n",
    "\n",
    "                for comp in range(3):\n",
    "                    slice_arrays.append(x_slice[..., comp])  \n",
    "                    slice_titles.append(f\"{var} (component {comp}) nnx=0 Timestep={t}\")\n",
    "\n",
    "                    slice_arrays.append(y_slice[..., comp])\n",
    "                    slice_titles.append(f\"{var} (component {comp}) nny=0 Timestep={t}\")\n",
    "\n",
    "                    slice_arrays.append(z_slice[..., comp])\n",
    "                    slice_titles.append(f\"{var} (component {comp}) nnz=0 Timestep={t}\")\n",
    "\n",
    "            else:\n",
    "                # Scalar\n",
    "                x_slice = arr[t, :, :, 0]  # shape [z, y]\n",
    "                y_slice = arr[t, :, 0, :]  # shape [z, x]\n",
    "                z_slice = arr[t, 0, :, :]  # shape [y, x]\n",
    "\n",
    "                slice_arrays.extend([x_slice, y_slice, z_slice])\n",
    "                slice_titles.extend([\n",
    "                    f\"{var} nnx=0 Timestep={t}\",\n",
    "                    f\"{var} nny=0 Timestep={t}\",\n",
    "                    f\"{var} nnz=0 Timestep={t}\"\n",
    "                ])\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3) COLLECT MEAN TEMP ARRAYS ACROSS Z\n",
    "    # ------------------------------------------------------------------\n",
    "    # We'll do it for \"temperature\" only, so let's confirm it's in variables\n",
    "    # (If you have a different variable name for temperature, adapt accordingly.)\n",
    "    if \"temperature\" in ds:\n",
    "        lazy_mean_arrays = []\n",
    "        # We'll store the timesteps in order so we can line up results\n",
    "        mean_t_indices = []\n",
    "\n",
    "        z_indices = range(0, ds[\"temperature\"].shape[1], spacing)  # e.g. 0..2048..128\n",
    "\n",
    "        if data_type == \"zarr\":\n",
    "            # Build a list of lazy means\n",
    "            for t in timesteps:\n",
    "                # shape ~ [z, y, x] (if last dim is 1, we can .squeeze or do `[..., 0]`)\n",
    "                temp_t = ds[\"temperature\"][t, :, :, :, 0]\n",
    "\n",
    "                # pick out z_indices: shape [len(z_indices), y, x]\n",
    "                temp_sliced = temp_t[list(z_indices), :, :]\n",
    "\n",
    "                # lazy mean over y, x => shape [len(z_indices)]\n",
    "                z_means = temp_sliced.mean(axis=(1, 2))\n",
    "\n",
    "                lazy_mean_arrays.append(z_means)\n",
    "                mean_t_indices.append(t)\n",
    "\n",
    "            # We'll stack them so we have shape [nTimesteps, len(z_indices)]\n",
    "            # but we won't compute until later\n",
    "            if lazy_mean_arrays:\n",
    "                # da.stack requires a list of dask arrays\n",
    "                mean_temp_stack = da.stack(lazy_mean_arrays, axis=0)\n",
    "            else:\n",
    "                mean_temp_stack = None\n",
    "\n",
    "        else:\n",
    "            # \"original\" => not truly lazy, but let's just store them for consistency\n",
    "            mean_temp_stack = []\n",
    "            for t in timesteps:\n",
    "                temp_t = ds[\"temperature\"][t, :64, :64, :64, 0]  # or the full domain\n",
    "                # Actually this is not lazy, but we'll keep the approach\n",
    "                # You could do a loop or a partial approach if they're truly NumPy.\n",
    "                pass\n",
    "    else:\n",
    "        mean_temp_stack = None\n",
    "        mean_t_indices = []\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4) SINGLE COMPUTE FOR EVERYTHING\n",
    "    # ------------------------------------------------------------------\n",
    "    # - We have `slice_arrays` (some might be Dask, some might be NumPy).\n",
    "    # - We have `mean_temp_stack` (Dask or None).\n",
    "    # We want to do a single `.compute()` on them all if they're Dask.\n",
    "\n",
    "    # We'll gather them into a single list to compute in one pass\n",
    "    dask_objects = []\n",
    "    if slice_arrays:\n",
    "        dask_objects.extend(slice_arrays)\n",
    "    if mean_temp_stack is not None:\n",
    "        # It's a single dask.array, not a list\n",
    "        dask_objects.append(mean_temp_stack)\n",
    "\n",
    "    # If there's truly nothing to compute (edge case), just skip\n",
    "    if not dask_objects:\n",
    "        print(\"No slices or mean arrays found to compute.\")\n",
    "        return\n",
    "\n",
    "    print(\"Building Dask graph for slices + mean temperature. Now computing...\")\n",
    "\n",
    "    with ProgressBar():\n",
    "        computed_results = compute(*dask_objects)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 5) UNPACK RESULTS\n",
    "    # ------------------------------------------------------------------\n",
    "    # The first len(slice_arrays) items correspond to the slices, in order.\n",
    "    # Then, if mean_temp_stack is not None, the last item is that array.\n",
    "\n",
    "    if mean_temp_stack is not None:\n",
    "        slice_result_count = len(slice_arrays)  \n",
    "        slice_data_results = computed_results[:slice_result_count]\n",
    "        mean_temp_results = computed_results[-1]  # shape [nTimesteps, len(z_indices)]\n",
    "    else:\n",
    "        slice_data_results = computed_results\n",
    "        mean_temp_results = None\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 6) PLOT AND SAVE SLICE IMAGES\n",
    "    # ------------------------------------------------------------------\n",
    "    # We'll replicate the logic for saving each variable's slices to disk\n",
    "    # By looping over variables + timesteps again in the same order.\n",
    "\n",
    "    idx = 0\n",
    "    for var in variables:\n",
    "        var_folder = os.path.join(master_slice_folder, var)\n",
    "        os.makedirs(var_folder, exist_ok=True)\n",
    "\n",
    "        slices_per_ts = slice_counts_per_variable_timestep[var]\n",
    "\n",
    "        for t in timesteps:\n",
    "            # Grab the relevant slice results from slice_data_results\n",
    "            subset = slice_data_results[idx : idx + slices_per_ts]\n",
    "            subset_titles = slice_titles[idx : idx + slices_per_ts]\n",
    "\n",
    "            for data_slice, title_str in zip(subset, subset_titles):\n",
    "                plt.figure()\n",
    "                plt.imshow(data_slice)\n",
    "                plt.title(title_str)\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.colorbar()\n",
    "\n",
    "                safe_title = title_str.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                fname = os.path.join(var_folder, f\"{safe_title}.png\")\n",
    "                plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "            idx += slices_per_ts\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 7) PLOT AND SAVE MEAN TEMPERATURE\n",
    "    # ------------------------------------------------------------------\n",
    "    if mean_temp_results is not None:\n",
    "        # mean_temp_results shape: [num_timesteps, len(z_indices)]\n",
    "        # mean_t_indices: the actual timesteps\n",
    "        z_indices_list = list(range(0, ds[\"temperature\"].shape[1], spacing))\n",
    "\n",
    "        for row_i, t in enumerate(mean_t_indices):\n",
    "            xy_means = mean_temp_results[row_i]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(z_indices_list, xy_means, marker='o')\n",
    "            plt.title(f\"Mean Temperature across Z (t={t}, data_type={data_type})\")\n",
    "            plt.xlabel(\"Slice (Z)\")\n",
    "            plt.ylabel(\"Average Temperature\")\n",
    "\n",
    "            file_name = os.path.join(mean_output_folder, f\"mean_z_temperature_{data_type}_t_{t}.png\")\n",
    "            plt.savefig(file_name, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved plot as {file_name}\")\n",
    "\n",
    "    print(\"All slice plots and mean-temperature plots saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zarr - High Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:24:18.715493Z",
     "iopub.status.busy": "2025-01-15T18:24:18.715169Z",
     "iopub.status.idle": "2025-01-15T18:24:18.719592Z",
     "shell.execute_reply": "2025-01-15T18:24:18.719005Z",
     "shell.execute_reply.started": "2025-01-15T18:24:18.715477Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "process_dataset = \"high_rate\"\n",
    "\n",
    "ds = jhf_hr_zarr = zarr.open(stored_jhf_hr_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T18:24:21.966267Z",
     "iopub.status.busy": "2025-01-15T18:24:21.965977Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppose you've already got a dictionary-like `ds` with:\n",
    "# ds[\"energy\"], ds[\"temperature\"], ds[\"pressure\"], ds[\"velocity\"] \n",
    "# as Dask arrays (from .from_zarr), each shape ~ [time, z, y, x, (maybe 3 for velocity)]\n",
    "\n",
    "variables = [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "timesteps = range(0, ds[\"energy\"].shape[0], 5)  # or [0, 5, 10, ..., 105]\n",
    "\n",
    "plot_slices_and_mean(\n",
    "    ds,\n",
    "    variables,\n",
    "    timesteps,\n",
    "    data_type=\"zarr\",    # so we do the lazy means\n",
    "    spacing=128,         # how often to sample Z dimension for the mean\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Original NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-15T14:53:23.702012Z",
     "iopub.status.idle": "2025-01-15T14:53:23.702232Z",
     "shell.execute_reply": "2025-01-15T14:53:23.702126Z",
     "shell.execute_reply.started": "2025-01-15T14:53:23.702117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_mean_temp_across_z(data_arrays, timesteps=range(0, 106, 5), data_type=\"original\", spacing=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across X\n",
    "\n",
    "- [ ] TODO if necessary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
