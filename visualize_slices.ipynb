{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code used to sanity-check data: plotting raw and written files, calculating various statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:33:02.335428Z",
     "iopub.status.busy": "2025-01-15T22:33:02.335277Z",
     "iopub.status.idle": "2025-01-15T22:33:03.298499Z",
     "shell.execute_reply": "2025-01-15T22:33:03.297880Z",
     "shell.execute_reply.started": "2025-01-15T22:33:02.335395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:33:03.300271Z",
     "iopub.status.busy": "2025-01-15T22:33:03.299792Z",
     "iopub.status.idle": "2025-01-15T22:33:03.303184Z",
     "shell.execute_reply": "2025-01-15T22:33:03.302674Z",
     "shell.execute_reply.started": "2025-01-15T22:33:03.300252Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_hr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048high/stsabl2048high.zarr\"\n",
    "raw_jhf_hr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.000.nc\"\n",
    "raw_jhf_hr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.001.nc\"\n",
    "raw_jhf_hr_104_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.104.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:33:03.303872Z",
     "iopub.status.busy": "2025-01-15T22:33:03.303736Z",
     "iopub.status.idle": "2025-01-15T22:33:03.418785Z",
     "shell.execute_reply": "2025-01-15T22:33:03.418120Z",
     "shell.execute_reply.started": "2025-01-15T22:33:03.303860Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr = zarr.open(stored_jhf_hr_path)\n",
    "jhf_hr_netcdf_t0 = xr.open_dataset(raw_jhf_hr_0_path)\n",
    "jhf_hr_netcdf_t1 = xr.open_dataset(raw_jhf_hr_1_path)\n",
    "jhf_hr_netcdf_t104 = xr.open_dataset(raw_jhf_hr_104_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:33:03.419788Z",
     "iopub.status.busy": "2025-01-15T22:33:03.419635Z",
     "iopub.status.idle": "2025-01-15T22:33:03.453157Z",
     "shell.execute_reply": "2025-01-15T22:33:03.452375Z",
     "shell.execute_reply.started": "2025-01-15T22:33:03.419774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stored_jhf_lr_path = \"/home/idies/workspace/turbulence-ceph-staging/sciserver-turbulence/stsabl2048low/stsabl2048low.zarr\"\n",
    "raw_jhf_lr_0_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.000.nc\"\n",
    "raw_jhf_lr_1_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.001.nc\"\n",
    "raw_jhf_lr_19_path = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.019.nc\"\n",
    "\n",
    "\n",
    "jhf_lr_zarr = zarr.open(stored_jhf_lr_path)\n",
    "jhf_lr_netcdf_t0 = xr.open_dataset(raw_jhf_lr_0_path)\n",
    "jhf_lr_netcdf_t1 = xr.open_dataset(raw_jhf_lr_1_path)\n",
    "jhf_lr_netcdf_t19 = xr.open_dataset(raw_jhf_lr_19_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"cyan\">\n",
    "\n",
    "# Remember, data is saved in `nnz-nny-nnx`\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Quick-Verify Correctness of data\n",
    "\n",
    "1. Check if `data == 0`\n",
    "\n",
    "2. Pick one $64^3$ chunk and compare it to raw NetCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### `zarr.info`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['velocity'].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Indexing, Compare to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Checking whether field all zeros - True is bad!\")\n",
    "\n",
    "for t in range(105):\n",
    "    print(\"t=\", t, \" - \", np.all(jhf_hr_zarr['temperature'][t,:64,:64,:64,0] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][1,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2025-01-15T14:50:41.857673Z",
     "shell.execute_reply": "2025-01-15T14:50:41.857091Z",
     "shell.execute_reply.started": "2025-01-15T14:44:20.357009Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  97 True\n",
      "t:  98 True\n",
      "t:  99 True\n",
      "t:  100 True\n",
      "t:  101 True\n",
      "t:  102 True\n",
      "t:  103 True\n",
      "t:  104 True\n"
     ]
    }
   ],
   "source": [
    "for t in range(93, 105):\n",
    "    zarr_comparison_data = jhf_hr_zarr['temperature'][t,:64,:64,:64,0]\n",
    "\n",
    "    raw_t_path = f\"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.{t:03d}.nc\"\n",
    "    raw_xr = xr.open_dataset(raw_t_path)\n",
    "    raw_t = raw_xr['t'].isel(nnx=slice(0, 64), nny=slice(0, 64), nnz=slice(0, 64)).values\n",
    "    \n",
    "    print(\"t: \", t, np.all(zarr_comparison_data == raw_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['temperature'][0,0,0,:10,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jhf_hr_zarr['energy'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_hr_netcdf_t0['e'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Xarray complains about missing metadata. NOT Fixed by GPT o1\n",
    "\n",
    "`written_ds_xr = xr.open_dataset(stored_jhf_path, engine='zarr', consolidated=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][0, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['velocity'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.all(ds['energy'][100, :10,0,0, 0] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Real Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhf_lr_zarr['temperature'][0,:10,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array(jhf_lr_netcdf_t0['t'][:10,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Efficient Zarr full data Slice `z=0`\n",
    "\n",
    "This can take a few minutes\n",
    "\n",
    " Sciserver doesn't allow localhost connections, so can't use Dask Cluster console Sciserver doesn't allow localhost connections, so can't use Dask Cluster console\n",
    " \n",
    "<font color=\"green\"> Lazy loading speeds up reading times 10x+</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:48:21.984774Z",
     "iopub.status.busy": "2025-01-15T22:48:21.984516Z",
     "iopub.status.idle": "2025-01-15T22:48:21.998206Z",
     "shell.execute_reply": "2025-01-15T22:48:21.997679Z",
     "shell.execute_reply.started": "2025-01-15T22:48:21.984756Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'inferno'\n",
    "\n",
    "def process_zarr(stored_jhf_path, dataset):\n",
    "    if dataset not in ['hr', 'lr']:\n",
    "        raise ValueError(\"Dataset must be 'hr' or 'lr'.\")\n",
    "\n",
    "    # Open the Zarr group\n",
    "    store = zarr.open_group(stored_jhf_path, mode='r')\n",
    "\n",
    "    # Create Dask arrays for each variable\n",
    "    data_arrays = {}\n",
    "    variables = list(store.array_keys())\n",
    "    for var_name in variables:\n",
    "        zarr_array = store[var_name]\n",
    "        dask_array = da.from_zarr(zarr_array)\n",
    "        # Squeeze scalar variables so that shape becomes [time, Z, Y, X]\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)\n",
    "        data_arrays[var_name] = dask_array\n",
    "\n",
    "    # Function to collect data slices\n",
    "    def collect_data_slices(data_arrays, variables, timesteps):\n",
    "        data_slices = []\n",
    "        titles = []\n",
    "        for variable in variables:\n",
    "            for timestep in timesteps:\n",
    "                dask_array = data_arrays[variable]\n",
    "                # Get slices along each dimension (assuming shape = [time, Z, Y, X] or similar)\n",
    "                x_slice = dask_array[timestep, :, :, 0]\n",
    "                y_slice = dask_array[timestep, :, 0, :]\n",
    "                z_slice = dask_array[timestep, 0, :, :]\n",
    "                \n",
    "                # For vector variables, handle components separately\n",
    "                if variable == 'velocity':\n",
    "                    for component in range(3):\n",
    "                        x_comp_slice = x_slice[..., component]\n",
    "                        y_comp_slice = y_slice[..., component]\n",
    "                        z_comp_slice = z_slice[..., component]\n",
    "                        data_slices.extend([x_comp_slice, y_comp_slice, z_comp_slice])\n",
    "                        titles.extend([\n",
    "                            f\"{variable} (component {component}) nnx=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nny=0 Timestep={timestep}\",\n",
    "                            f\"{variable} (component {component}) nnz=0 Timestep={timestep}\"\n",
    "                        ])\n",
    "                else:\n",
    "                    data_slices.extend([x_slice, y_slice, z_slice])\n",
    "                    titles.extend([\n",
    "                        f\"{variable} nnx=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nny=0 Timestep={timestep}\",\n",
    "                        f\"{variable} nnz=0 Timestep={timestep}\"\n",
    "                    ])\n",
    "        return data_slices, titles\n",
    "\n",
    "    # Choose timesteps: here every 5th timestep until the end\n",
    "    timesteps = range(0, data_arrays['energy'].shape[0], 5)  \n",
    "\n",
    "    # Collect data slices for selected variables and timesteps\n",
    "    data_slices, titles = collect_data_slices(\n",
    "        data_arrays, \n",
    "        ['energy', 'temperature', 'pressure', 'velocity'], \n",
    "        timesteps\n",
    "    )\n",
    "\n",
    "    # Compute all data slices at once (lazy evaluation: one single compute call)\n",
    "    with ProgressBar():\n",
    "        computed_slices = compute(*data_slices)\n",
    "\n",
    "    # Create a master folder for the dataset: zarr_slices/<dataset>\n",
    "    master_folder = os.path.join(\"zarr_slices\", dataset)\n",
    "    os.makedirs(master_folder, exist_ok=True)\n",
    "\n",
    "    # For each variable, create a subfolder inside the dataset folder\n",
    "    variables_to_process = ['energy', 'temperature', 'pressure', 'velocity']\n",
    "    for var in variables_to_process:\n",
    "        var_folder = os.path.join(master_folder, var)\n",
    "        os.makedirs(var_folder, exist_ok=True)\n",
    "\n",
    "    # We'll have 3 slices per timestep for scalar variables,\n",
    "    # and 9 slices per timestep for velocity (3 components × 3 slices).\n",
    "    slices_per_timestep = {\n",
    "        'energy': 3,\n",
    "        'temperature': 3,\n",
    "        'pressure': 3,\n",
    "        'velocity': 9\n",
    "    }\n",
    "\n",
    "    # Loop over each variable and each timestep to save the plots\n",
    "    idx = 0\n",
    "    for variable in variables_to_process:\n",
    "        var_folder = os.path.join(master_folder, variable)\n",
    "        for timestep in timesteps:\n",
    "            subset = computed_slices[idx : idx + slices_per_timestep[variable]]\n",
    "            subset_titles = titles[idx : idx + slices_per_timestep[variable]]\n",
    "            for data_slice, title in zip(subset, subset_titles):\n",
    "                plt.figure()\n",
    "                plt.imshow(data_slice)\n",
    "                plt.title(title)\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.colorbar()\n",
    "                \n",
    "                # Create a filename for saving in the variable subfolder\n",
    "                safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                filename = os.path.join(var_folder, f\"Timestep_{timestep}_{safe_title}.png\")\n",
    "                plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "                plt.close()\n",
    "            idx += slices_per_timestep[variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:48:23.431752Z",
     "iopub.status.busy": "2025-01-15T22:48:23.431353Z",
     "iopub.status.idle": "2025-01-15T22:50:02.069456Z",
     "shell.execute_reply": "2025-01-15T22:50:02.068641Z",
     "shell.execute_reply.started": "2025-01-15T22:48:23.431726Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 45.81 s\n"
     ]
    }
   ],
   "source": [
    "process_zarr(stored_jhf_lr_path, \"lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:50:02.070688Z",
     "iopub.status.busy": "2025-01-15T22:50:02.070533Z",
     "iopub.status.idle": "2025-01-15T22:54:24.947810Z",
     "shell.execute_reply": "2025-01-15T22:54:24.946273Z",
     "shell.execute_reply.started": "2025-01-15T22:50:02.070669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##########                              ] | 25% Completed | 195.81 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_zarr(stored_jhf_hr_path, \"hr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Combined Mean Temp and Slice Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:55:08.013368Z",
     "iopub.status.busy": "2025-01-15T22:55:08.013101Z",
     "iopub.status.idle": "2025-01-15T22:55:08.033120Z",
     "shell.execute_reply": "2025-01-15T22:55:08.032568Z",
     "shell.execute_reply.started": "2025-01-15T22:55:08.013349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask.array as da\n",
    "from dask import compute\n",
    "from dask.diagnostics import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_slices_and_mean_z(\n",
    "    ds_zarr_group, \n",
    "    variables, \n",
    "    time_start=0, \n",
    "    time_stop=105, \n",
    "    time_step=5, \n",
    "    z_step=128,\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Creates a Dask array for each variable from the Zarr group ds_zarr_group.\n",
    "    2) Gathers slice arrays (X=0, Y=0, and Z=range(0, z_dim, z_step)) for each variable/time.\n",
    "    3) Optionally gathers the mean-temp-across-Z (every z_step along Z).\n",
    "    4) Performs exactly one .compute() to load everything.\n",
    "    5) Plots and/or saves images if the respective output folder is provided.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_zarr_group : zarr.hierarchy.Group\n",
    "        A Zarr group, e.g. from zarr.open_group(...), with arrays named by `variables`.\n",
    "        Each array shape typically [time, z, y, x, 1 or 3].\n",
    "    variables : list of str\n",
    "        E.g. [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "    time_start, time_stop, time_step : int\n",
    "        We will process times in range(time_start, time_stop, time_step).\n",
    "        Make sure time_stop <= ds['temperature'].shape[0] (if you use 'temperature').\n",
    "    z_step : int\n",
    "        Step size along Z dimension for the z-slice plotting,\n",
    "        and also for the mean calculation if mean_output_folder is not None.\n",
    "    master_slice_folder : str or None\n",
    "        Where to save slice images. If None, skip slice plotting & saving altogether.\n",
    "    mean_output_folder : str or None\n",
    "        Where to save mean-temperature plots. If None, skip mean-temperature calculation/plotting.\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 1) Convert each Zarr array to a Dask array (lazy)\n",
    "    # -------------------------------------------------------------------------\n",
    "    data_arrays = {}\n",
    "    for var in variables:\n",
    "        zarr_array = ds_zarr_group[var]  # shape e.g. (105, 2048, 2048, 2048, 1)\n",
    "        dask_array = da.from_zarr(zarr_array)  # now a Dask array, fully lazy\n",
    "        # If last dim == 1, squeeze it out => shape => (time, z, y, x)\n",
    "        if dask_array.shape[-1] == 1:\n",
    "            dask_array = dask_array.squeeze(axis=-1)\n",
    "        data_arrays[var] = dask_array\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 2) Build slices for time and for z\n",
    "    # -------------------------------------------------------------------------\n",
    "    # We'll do time slicing using slice(time_start, time_stop, time_step).\n",
    "    # e.g. if time_start=0, time_stop=105, time_step=5 => times = [0,5,10,...,100]\n",
    "    time_slice = slice(time_start, time_stop, time_step)\n",
    "    \n",
    "    # For the z dimension in the \"z-slice\" plotting, we want every z_step\n",
    "    # from z=0..(z_dim). So we do z_slice = slice(None, None, z_step)\n",
    "    z_slice = slice(None, None, z_step)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3a) Gather slice arrays: X=0, Y=0, Z=range(0, z_dim, z_step)\n",
    "    # -------------------------------------------------------------------------\n",
    "    slice_arrays = []   # each item will be a Dask array\n",
    "    slice_titles = []   # matching titles\n",
    "\n",
    "    for var in variables:\n",
    "        arr = data_arrays[var]  \n",
    "        # shape => (time, z, y, x) or (time, z, y, x, 3) if velocity was not squeezed\n",
    "\n",
    "        if (var == \"velocity\") and (arr.ndim == 5):\n",
    "            # Velocity shape => (time, z, y, x, 3)\n",
    "            for comp in range(3):\n",
    "                # X=0 => arr[time_slice, :, :, 0, comp]\n",
    "                vx0 = arr[time_slice, :, :, 0, comp]\n",
    "                slice_arrays.append(vx0)\n",
    "                slice_titles.append(f\"{var} (comp {comp}) x=0\")\n",
    "\n",
    "                # Y=0 => arr[time_slice, :, 0, :, comp]\n",
    "                vy0 = arr[time_slice, :, 0, :, comp]\n",
    "                slice_arrays.append(vy0)\n",
    "                slice_titles.append(f\"{var} (comp {comp}) y=0\")\n",
    "\n",
    "                # Z= every z_step => arr[time_slice, ::z_step, :, :, comp]\n",
    "                vzAll = arr[time_slice, z_slice, :, :, comp]\n",
    "                slice_arrays.append(vzAll)\n",
    "                slice_titles.append(f\"{var} (comp {comp}) z=all(step={z_step})\")\n",
    "\n",
    "        else:\n",
    "            # Scalar variable shape => (time, z, y, x)\n",
    "            # X=0\n",
    "            x0 = arr[time_slice, :, :, 0]\n",
    "            slice_arrays.append(x0)\n",
    "            slice_titles.append(f\"{var} x=0\")\n",
    "\n",
    "            # Y=0\n",
    "            y0 = arr[time_slice, :, 0, :]\n",
    "            slice_arrays.append(y0)\n",
    "            slice_titles.append(f\"{var} y=0\")\n",
    "\n",
    "            # Z= every z_step => arr[time_slice, ::z_step, :, :]\n",
    "            zAll = arr[time_slice, z_slice, :, :]\n",
    "            slice_arrays.append(zAll)\n",
    "            slice_titles.append(f\"{var} z=all(step={z_step})\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 3b) Gather the Dask array for \"mean temperature across Z\" (optional)\n",
    "    # -------------------------------------------------------------------------\n",
    "    mean_temp_dask = None\n",
    "    if (mean_output_folder is not None) and (\"temperature\" in data_arrays):\n",
    "        temp_arr = data_arrays[\"temperature\"]  # shape => (time, z, y, x)\n",
    "        stepped = temp_arr[time_slice, z_slice, :, :]  # [time, #z_slices, y, x]\n",
    "        # Mean over y,x => shape => [num_times, #z_slices]\n",
    "        mean_temp_dask = stepped.mean(axis=(2, 3))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 4) Single .compute() for all\n",
    "    # -------------------------------------------------------------------------\n",
    "    to_compute = slice_arrays[:]\n",
    "    if mean_temp_dask is not None:\n",
    "        to_compute.append(mean_temp_dask)\n",
    "\n",
    "    if not to_compute:\n",
    "        print(\"No data to load or compute. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Building Dask graph (lazy). Now calling .compute() with a ProgressBar...\")\n",
    "    with ProgressBar():\n",
    "        results = compute(*to_compute)\n",
    "    slice_results = results[:len(slice_arrays)]\n",
    "    mean_results = results[-1] if mean_temp_dask is not None else None\n",
    "\n",
    "    # Build the list of timesteps actually used\n",
    "    times = list(range(time_start, time_stop, time_step))\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 5) Plot & Save the slice results (if master_slice_folder is not None)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if master_slice_folder is not None:\n",
    "        os.makedirs(master_slice_folder, exist_ok=True)\n",
    "        print(\"Plotting slice images to:\", master_slice_folder)\n",
    "\n",
    "        for slice_result, title in zip(slice_results, slice_titles):\n",
    "            # slice_result shape can be:\n",
    "            #   [num_times, z, y]   if x=0\n",
    "            #   [num_times, z, x]   if y=0\n",
    "            #   [num_times, #z_slices, y, x] if it's the z= slice\n",
    "            #\n",
    "            # We'll do a for-loop over times, then if there's an extra dimension\n",
    "            # for #z_slices, we do another nested loop.\n",
    "\n",
    "            for i, t in enumerate(times):\n",
    "                data_for_this_time = slice_result[i] \n",
    "                # data_for_this_time shape => [z,y], [z,x], or [#z_slices, y, x], etc.\n",
    "\n",
    "                if data_for_this_time.ndim == 2:\n",
    "                    # Single 2D slice: Just plot once\n",
    "                    plt.figure()\n",
    "                    plt.imshow(data_for_this_time)\n",
    "                    plt.gca().invert_yaxis()\n",
    "                    plt.colorbar()\n",
    "                    plt.title(f\"{title}, t={t}\")\n",
    "\n",
    "                    safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                    fname = os.path.join(\n",
    "                        master_slice_folder, \n",
    "                        f\"{safe_title}_t_{t}.png\"\n",
    "                    )\n",
    "                    plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "\n",
    "                elif data_for_this_time.ndim == 3:\n",
    "                    # shape => [numZ, y, x], so we have multiple slices\n",
    "                    numZ = data_for_this_time.shape[0]\n",
    "                    for z_i in range(numZ):\n",
    "                        single_slice = data_for_this_time[z_i]  # shape => [y, x]\n",
    "\n",
    "                        plt.figure()\n",
    "                        plt.imshow(single_slice)\n",
    "                        plt.gca().invert_yaxis()\n",
    "                        plt.colorbar()\n",
    "                        plt.title(f\"{title}, t={t}, zstep_idx={z_i}\")\n",
    "\n",
    "                        safe_title = title.replace(\" \", \"_\").replace(\"=\", \"_\")\n",
    "                        fname = os.path.join(\n",
    "                            master_slice_folder, \n",
    "                            f\"{safe_title}_t_{t}_zidx_{z_i}.png\"\n",
    "                        )\n",
    "                        plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "                        plt.close()\n",
    "                else:\n",
    "                    print(f\"Warning: Unexpected shape {data_for_this_time.shape} for {title}, skipping plot.\")\n",
    "\n",
    "        print(\"Done plotting slices!\")\n",
    "    else:\n",
    "        print(\"master_slice_folder=None => Skipping slice plotting.\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 6) Plot the mean temperature results (if mean_output_folder and mean_results)\n",
    "    # -------------------------------------------------------------------------\n",
    "    if mean_results is not None:\n",
    "        os.makedirs(mean_output_folder, exist_ok=True)\n",
    "        print(\"Plotting mean temperature to:\", mean_output_folder)\n",
    "\n",
    "        # mean_results shape => [num_times, #z_slices]\n",
    "        # The z_slices are from z=0..(some max).. step z_step\n",
    "        z_indices_list = list(range(0, data_arrays[\"temperature\"].shape[1], z_step))\n",
    "\n",
    "        for i, t in enumerate(times):\n",
    "            row = mean_results[i]  # shape => [#z_slices]\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(z_indices_list, row)\n",
    "            plt.title(f\"Mean Temperature across Z (t={t})\")\n",
    "            plt.xlabel(\"Z index\")\n",
    "            plt.ylabel(\"Avg Temp\")\n",
    "            \n",
    "            fname = os.path.join(mean_output_folder, f\"mean_z_temperature_t_{t}.png\")\n",
    "            plt.savefig(fname, dpi=150, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            print(f\"Saved plot as {fname}\")\n",
    "    else:\n",
    "        if mean_output_folder is None:\n",
    "            print(\"mean_output_folder=None => Skipping mean temperature calculation and plots.\")\n",
    "        else:\n",
    "            print(\"No temperature array or empty results => skipping mean temperature.\")\n",
    "    \n",
    "    print(\"All done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zarr\n",
    "\n",
    "### High Rate\n",
    "\n",
    "- [ ] TODO this needs editing to add HR plots to HR folder, LR plots to own folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Across Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:56:47.457955Z",
     "iopub.status.busy": "2025-01-15T22:56:47.457702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Dask graph (lazy). Now calling .compute() with a ProgressBar...\n"
     ]
    }
   ],
   "source": [
    "variables = [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "\n",
    "plot_slices_and_mean_z(\n",
    "    ds_zarr_group=jhf_hr_zarr,\n",
    "    variables=variables,\n",
    "    time_start=0,\n",
    "    time_stop=105,  # up to but not including 105 => indices 0..104\n",
    "    time_step=5,\n",
    "    z_step=16,\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables = [\"energy\", \"temperature\", \"pressure\", \"velocity\"]\n",
    "\n",
    "plot_slices_and_mean_z(\n",
    "    ds_zarr_group=jhf_lr_zarr,\n",
    "    variables=variables,\n",
    "    time_start=0,\n",
    "    time_stop=20,  # up to but not including 105 => indices 0..104\n",
    "    time_step=2,\n",
    "    z_step=16,\n",
    "    master_slice_folder=\"zarr_slices\",\n",
    "    mean_output_folder=\"mean_temperature_plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across X\n",
    "\n",
    "- [ ] TODO if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Original NetCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-15T14:53:23.702012Z",
     "iopub.status.idle": "2025-01-15T14:53:23.702232Z",
     "shell.execute_reply": "2025-01-15T14:53:23.702126Z",
     "shell.execute_reply.started": "2025-01-15T14:53:23.702117Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_mean_temp_across_z(data_arrays, timesteps=range(0, 106, 5), data_type=\"original\", spacing=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compare Zarr to NetCDF correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T22:41:13.286488Z",
     "iopub.status.busy": "2025-01-15T22:41:13.286249Z",
     "iopub.status.idle": "2025-01-15T22:41:13.302398Z",
     "shell.execute_reply": "2025-01-15T22:41:13.301836Z",
     "shell.execute_reply.started": "2025-01-15T22:41:13.286473Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask import compute\n",
    "import xarray as xr\n",
    "\n",
    "def compare_zarr_and_netcdf_allvars(\n",
    "    zarr_group,\n",
    "    netcdf_path_pattern,\n",
    "    times=range(0, 105),  # valid time indices\n",
    "    z_slice=64,\n",
    "    y_slice=64,\n",
    "    x_slice=64,\n",
    "    netcdf_chunk=64\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare all JHF variables between a Zarr group and multiple NetCDF files \n",
    "    for the given timesteps, using lazy Dask operations in one pass.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zarr_group : zarr.hierarchy.Group\n",
    "        Zarr group containing the 4 JHF variables:\n",
    "        [\"temperature\", \"pressure\", \"energy\", \"velocity\"].\n",
    "        Each variable is shape [time, z, y, x, (1 or 3)].\n",
    "    netcdf_path_pattern : str\n",
    "        File path pattern for NetCDF files. \n",
    "        E.g. \"/path/to/jhf.*.nc\" if each file is one timestep.\n",
    "    times : iterable\n",
    "        Timestep indices (e.g. range(0,105)) to compare in one go.\n",
    "    z_slice, y_slice, x_slice : int\n",
    "        Compare subregion [0:z_slice, 0:y_slice, 0:x_slice].\n",
    "        Typically something small for quick checks (64, 128, etc.).\n",
    "    netcdf_chunk : int\n",
    "        Chunk size to use for opening NetCDF \n",
    "        (e.g. 64 => chunks={\"nnz\": 64, \"nny\": 64, \"nnx\": 64}).\n",
    "    \"\"\"\n",
    "\n",
    "    #---------------------\n",
    "    # 1) OPEN NETCDF\n",
    "    #---------------------\n",
    "    ds_nc = xr.open_mfdataset(\n",
    "        netcdf_path_pattern,\n",
    "        combine=\"nested\",\n",
    "        concat_dim=\"time\",\n",
    "        parallel=True,\n",
    "        chunks={\"nnz\": netcdf_chunk, \"nny\": netcdf_chunk, \"nnx\": netcdf_chunk}\n",
    "    )\n",
    "    # The NetCDF variables we expect: \"t\", \"p\", \"e\", \"u\", \"v\", \"w\"\n",
    "    # Each file is presumably one time step, stacked along \"time\".\n",
    "\n",
    "    #---------------------\n",
    "    # 2) PREP Zarr as Dask arrays\n",
    "    #---------------------\n",
    "    # We'll create xarray or Dask arrays from the Zarr group.\n",
    "    # That ensures everything is truly lazy until .compute().\n",
    "    var_map = {}\n",
    "    for var in [\"temperature\", \"pressure\", \"energy\", \"velocity\"]:\n",
    "        zarr_array = zarr_group[var]  # e.g. shape [time, z, y, x, 3 or 1]\n",
    "        # Convert to a Dask array:\n",
    "        dask_arr = da.from_zarr(zarr_array)\n",
    "        # If last dim == 1, squeeze it out so shape becomes [time, z, y, x]\n",
    "        if dask_arr.shape[-1] == 1:\n",
    "            dask_arr = dask_arr.squeeze(axis=-1)\n",
    "        # Wrap it in an xarray.DataArray for easier .isel():\n",
    "        var_map[var] = xr.DataArray(\n",
    "            dask_arr,\n",
    "            dims=(\"time\", \"z\", \"y\", \"x\") if var != \"velocity\" else (\"time\", \"z\", \"y\", \"x\", \"component\")\n",
    "        )\n",
    "\n",
    "    #---------------------\n",
    "    # 3) BUILD COMPARISON\n",
    "    #---------------------\n",
    "    # We'll compare these variable pairs:\n",
    "    #   Zarr => NetCDF\n",
    "    #   \"temperature\" => \"t\"\n",
    "    #   \"pressure\"    => \"p\"\n",
    "    #   \"energy\"      => \"e\"\n",
    "    #   \"velocity\"[..., comp=0] => \"u\"\n",
    "    #   \"velocity\"[..., comp=1] => \"v\"\n",
    "    #   \"velocity\"[..., comp=2] => \"w\"\n",
    "    # We'll gather all eq_arrays in a list, then do one single compute.\n",
    "    eq_arrays = []\n",
    "    eq_descriptions = []\n",
    "\n",
    "    # Helper to slice netcdf\n",
    "    def slice_nc(var_name):\n",
    "        return ds_nc[var_name].isel(\n",
    "            time=times, \n",
    "            nnz=slice(0, z_slice), \n",
    "            nny=slice(0, y_slice), \n",
    "            nnx=slice(0, x_slice)\n",
    "        )\n",
    "    # Helper to slice zarr\n",
    "    def slice_zarr(var_name):\n",
    "        # if \"velocity\", we'll handle it separately below\n",
    "        return var_map[var_name].isel(\n",
    "            time=slice(min(times), max(times)+1),  # a bit broader, then we'll index in a second step\n",
    "            z=slice(0, z_slice),\n",
    "            y=slice(0, y_slice),\n",
    "            x=slice(0, x_slice),\n",
    "        ).isel(time=times if isinstance(times, list) else range(len(times)))\n",
    "        # Explanation: if `times` is e.g. range(0,105,5), xarray can handle slice. \n",
    "        # If you pass a range object directly, xarray handles it. \n",
    "        # Or we cast to a list to ensure it can index properly.\n",
    "\n",
    "    # Compare temperature => t\n",
    "    if \"temperature\" in var_map and \"t\" in ds_nc.variables:\n",
    "        zarr_temp = slice_zarr(\"temperature\")\n",
    "        nc_temp   = slice_nc(\"t\")\n",
    "        eq_temp   = (zarr_temp == nc_temp)\n",
    "        eq_arrays.append(eq_temp) \n",
    "        eq_descriptions.append(\"temperature vs t\")\n",
    "\n",
    "    # Compare pressure => p\n",
    "    if \"pressure\" in var_map and \"p\" in ds_nc.variables:\n",
    "        zarr_pres = slice_zarr(\"pressure\")\n",
    "        nc_pres   = slice_nc(\"p\")\n",
    "        eq_pres   = (zarr_pres == nc_pres)\n",
    "        eq_arrays.append(eq_pres)\n",
    "        eq_descriptions.append(\"pressure vs p\")\n",
    "\n",
    "    # Compare energy => e\n",
    "    if \"energy\" in var_map and \"e\" in ds_nc.variables:\n",
    "        zarr_ener = slice_zarr(\"energy\")\n",
    "        nc_ener   = slice_nc(\"e\")\n",
    "        eq_ener   = (zarr_ener == nc_ener)\n",
    "        eq_arrays.append(eq_ener)\n",
    "        eq_descriptions.append(\"energy vs e\")\n",
    "\n",
    "    # Compare velocity => (u, v, w)\n",
    "    if \"velocity\" in var_map and all(comp in ds_nc.variables for comp in [\"u\", \"v\", \"w\"]):\n",
    "        # shape => [time, z, y, x, component=3]\n",
    "        zarr_vel = var_map[\"velocity\"].isel(\n",
    "            time=slice(min(times), max(times)+1),\n",
    "            z=slice(0, z_slice),\n",
    "            y=slice(0, y_slice),\n",
    "            x=slice(0, x_slice),\n",
    "        ).isel(time=times if isinstance(times, list) else range(len(times)))\n",
    "\n",
    "        for comp_idx, comp_name in enumerate([\"u\", \"v\", \"w\"]):\n",
    "            nc_comp = slice_nc(comp_name)  # shape [time, nnz, nny, nnx]\n",
    "            zarr_comp = zarr_vel.isel(component=comp_idx)  # shape [time, z, y, x]\n",
    "            eq_comp = (zarr_comp == nc_comp)\n",
    "            eq_arrays.append(eq_comp)\n",
    "            eq_descriptions.append(f\"velocity[{comp_idx}] vs {comp_name}\")\n",
    "\n",
    "    # If eq_arrays is empty, no matching variables found\n",
    "    if not eq_arrays:\n",
    "        print(\"No matching variables to compare!\")\n",
    "        ds_nc.close()\n",
    "        return\n",
    "\n",
    "    #---------------------\n",
    "    # 4) SINGLE COMPUTE\n",
    "    #---------------------\n",
    "    print(f\"Built {len(eq_arrays)} comparisons. Now computing with Dask (lazy).\")\n",
    "    with ProgressBar():\n",
    "        eq_results = compute(*eq_arrays)\n",
    "        # eq_results is a tuple of bool xarray.DataArray objects.\n",
    "\n",
    "    #---------------------\n",
    "    # 5) REPORT PER TIMESTEP\n",
    "    #---------------------\n",
    "    # Each eq_result => shape [time, z_slice, y_slice, x_slice], boolean\n",
    "    # We'll do a .all(dim=[\"z\",\"y\",\"x\"]) => shape [time], for each eq_result.\n",
    "    # Then print out each time’s True/False. \n",
    "    # If you used different dim names, adapt accordingly.\n",
    "\n",
    "    # Convert `times` to a list to iterate easily\n",
    "    times_list = list(times)  # e.g. [0,1,2,...,104] or some subset\n",
    "    for eq_array, desc in zip(eq_results, eq_descriptions):\n",
    "        # eq_array is an xarray.DataArray of shape [time, z_slice, y_slice, x_slice]\n",
    "        # Do a .all over spatial dims\n",
    "        # If dims are named (\"time\", \"z\", \"y\", \"x\"), we do eq_array.all(dim=[\"z\",\"y\",\"x\"])\n",
    "        # If they’re named differently, adapt.\n",
    "        eq_per_t = eq_array.all(dim=(\"z\",\"y\",\"x\"))\n",
    "\n",
    "        print(f\"\\n=== {desc} ===\")\n",
    "        for i, tval in enumerate(times_list):\n",
    "            is_match = bool(eq_per_t[i].values)  # True/False\n",
    "            print(f\"  t={tval}, match={is_match}\")\n",
    "\n",
    "    ds_nc.close()\n",
    "    print(\"Comparison done. All NetCDF files closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2) Provide the NetCDF path pattern\n",
    "nc_pattern = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/hr/jhf.*.nc\"  \n",
    "# (Assumes jhf.000.nc, jhf.001.nc, ... each containing variables t, p, e, u, v, w)\n",
    "\n",
    "# 3) Choose timesteps and slice sizes\n",
    "times_to_compare = range(0, 105, 5)  # e.g. [0, 5, 10, 15, ..., 100]\n",
    "z_slice_size = 64\n",
    "y_slice_size = 64\n",
    "x_slice_size = 64\n",
    "\n",
    "compare_zarr_and_netcdf_allvars(\n",
    "    zarr_group=jhf_hr_zarr,\n",
    "    netcdf_path_pattern=nc_pattern,\n",
    "    times=times_to_compare,\n",
    "    z_slice=z_slice_size,\n",
    "    y_slice=y_slice_size,\n",
    "    x_slice=x_slice_size,\n",
    "    netcdf_chunk=64  # netCDF chunk in nnz, nny, nnx\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-15T22:30:13.358604Z",
     "iopub.status.idle": "2025-01-15T22:30:13.358793Z",
     "shell.execute_reply": "2025-01-15T22:30:13.358704Z",
     "shell.execute_reply.started": "2025-01-15T22:30:13.358695Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2) Provide the NetCDF path pattern\n",
    "nc_pattern = \"/home/idies/workspace/turbulence-ceph-staging/ncar-jhf/lr/jhf.*.nc\"  \n",
    "# (Assumes jhf.000.nc, jhf.001.nc, ... each containing variables t, p, e, u, v, w)\n",
    "\n",
    "# 3) Choose timesteps and slice sizes\n",
    "times_to_compare = range(0, 20, 5)  # e.g. [0, 5, 10, 15, ..., 100]\n",
    "z_slice_size = 64\n",
    "y_slice_size = 64\n",
    "x_slice_size = 64\n",
    "\n",
    "# 4) Call the function\n",
    "compare_zarr_and_netcdf_allvars(\n",
    "    zarr_group=jhf_hr_zarr,\n",
    "    netcdf_path_pattern=nc_pattern,\n",
    "    times=times_to_compare,\n",
    "    z_slice=z_slice_size,\n",
    "    y_slice=y_slice_size,\n",
    "    x_slice=x_slice_size,\n",
    "    netcdf_chunk=64  # netCDF chunk in nnz, nny, nnx\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
